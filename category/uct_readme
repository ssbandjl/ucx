术语:
LAG (Link Aggregation Group): 链路汇聚(bonding), 网络绑定可以将两个或多个网络接口组合成一个接口。它可以提高网络吞吐量和带宽，并在其中一个接口发生故障时提供冗余。NVIDIA ® BlueField ® DPU 可以选择以对主机透明的方式在 Arm 端配置网络绑定。在这种配置下，主机只能看到一个 PF, 参考: https://docs.nvidia.com/networking/display/bluefielddpuosv385/link+aggregation

seg: Size of each RMPP segment, 每个 RMPP 段的大小, 可靠多分组处理, https://patents.google.com/patent/CN104205079B/zh, RMPP(可靠多分组处理)头部部分、SA头部、SA记录以及SA数据部分。SA头部可包括可包含RDMA启用标志的一个或多个保留字段。RMPP头部包括用于使卸载引擎能处理分组分段和重组的信息。存在各种类型的SA数据。这些类型被定义为“记录”。每个记录描述有关网络或网络上的节点的不同类型的信息。示例性记录包括例如描述有关交换机的信息、描述节点信息的记录、用于性能计数器的记录等等。这些记录是正在被请求的实际数据。这些头部用于标识查询和响应，从而使得响应可与正确的查询匹配






API头文件: src/uct/api/uct.h
内存域资源描述符: typedef struct uct_md_resource_desc

接口属性(能力和限制), 嵌套结构体: struct uct_iface_attr

分散聚集IO, sgl, SGL, 聚散表: typedef struct uct_iov
stride: 1个内存跨度,范围, 所有 iov 列表中的长度总和必须小于或等于相应通信操作的 max_zcopy。 如果长度或计数为零，则不会访问 buffer 指向的内存。 否则，缓冲区必须指向有效的内存。 如果 count 为 1，则每个 iov 条目指定单个连续数据块 如果 count > 1，则每个 iov 条目指定 count 元素的跨步块以及连续元素之间的跨步字节距离


先执行一次: cd example; ./uct_hello_world


uct_example: uct_hello_world.c
启用编译: export HAVE_EXAMPLES=true
bash examples/uct_hello_world
server:  exec /home/xb/project/ucx/examples/.libs/lt-uct_hello_world -d ib17-0 -t tcp
gdb --args /home/xb/project/ucx/examples/.libs/lt-uct_hello_world -d mlx5_0:1 -t rc_verbs


主流程(服务端或客户端): 
1. 主函数中解析命令行参数(parse_cmd), 设置默认服务端口
2. 初始化上下文(ucs_async_context_create, 异步事件上下文用于管理定时器和FD通知), 在其中, 初始化多生产者/多消费者队列(ucs_mpmc_queue_init), 初始化非阻塞异步轮询器(ucs_async_poll_init), 初始化可重入自旋锁上下文等
3. 创建工人(uct_worker_create), 工人代表着 progress 的引擎。 可以在应用程序中创建多个进度引擎，例如供多个线程使用
4. 根据入参查找期望的传输层(dev_tl_lookup, 由最小延迟决定要使用的设备和传输)
5. 设置回调(uct_iface_set_am_handler), 设置服务端接收到客户端数据后的回调
6. 建立socket连接(connect_common), 服务端监听端口, 等待客户端发起socket连接
7. 客户端连接服务端后, 两边交换地址(sendrecv, 先通过socket发送和接收长度, 然后发送和接收地址, 交换地址)
8. 创建端点(uct_ep_create), 获取端点地址(uct_ep_get_address), 连接对等端点(uct_ep_connect_to_ep, 内部通过 ibv_modify_qp 设置QP状态机建立QP连接)
9. 连接建立后, 客户端调用短消息(do_am_short)/缓冲区(do_am_bcopy)/零拷贝(do_am_zcopy)发送数据
10. 显示驱动工人推进(uct_worker_progress, 该例程显式地处理任何未完成的通信操作和活动消息请求, 底层通过poll网卡完成事件,ibv_poll_cq)
11. 资源销毁(uct_ep_destroy,free其他资源等)


启动服务端: 
gdb: examples/uct_hello_world.c -> int main(int argc, char **argv)
  if (parse_cmd(argc, argv, &cmd_args)) -> int parse_cmd(int argc, char * const argv[], cmd_args_t *args)
    args->server_port   = 13337
  status = ucs_async_context_create(UCS_ASYNC_MODE_THREAD_SPINLOCK, &async) -> 创建异步执行上下文, 分配并初始化异步执行上下文。 这可用于确保安全的事件传递, 模式为线程自旋锁(可重入), 在异步对象上, 初始化多生产者和多消费者队列
    async = ucs_malloc(sizeof(*async), "async context") -> 内部分配, 并记录内存分配信息
      void *ptr = malloc(size)
    status = ucs_async_context_init(async, mode)
      ucs_trace_func("async=%p", async) -> 跟踪方法
      status = ucs_mpmc_queue_init(&async->missed) -> 初始化多生产者/多消费者队列
        ucs_queue_head_init(&mpmc->queue)
        pthread_spin_init(&lock->lock, lock_flags) -> 初始化自旋锁, 标志: PTHREAD_PROCESS_SHARED 或 PTHREAD_PROCESS_PRIVATE
      status = ucs_async_method_call(mode, context_init, async) -> .context_init       = ucs_async_poll_init -> 异步轮询初始化, 不阻塞
      async->last_wakeup = ucs_get_time() -> asm volatile("rdtsc" : "=a"(low), "=d"(high)) 汇编获取时间 -> UCS/ARCH/INFO：如果无法从CPU型号中读取x86 TSC值，请不要从/proc/cpuinfo中读取测量的CPU频率，因为它只能代表核心频率而不是TSC频率。 相反，通过一个短循环进行测量，当频率测量收敛或达到 1ms 时间限制时停止
        ucs_async_thread_spinlock_ops.context_init(async) -> ucs_async_thread_spinlock_init -> 可重入自旋锁上下文初始化
  status = uct_worker_create(async, UCS_THREAD_MODE_SINGLE, &if_info.worker) -> 创建工人(独立资源) -> UCS_CLASS_DEFINE_NAMED_NEW_FUNC(uct_worker_create -> 用宏初始化工人(类似面向对象实例化) -> 创建一个工作对象。 工人代表着progress的引擎。 可以在应用程序中创建多个进度引擎，例如供多个线程使用。 Transports 可以为每个 Worker 分配单独的通信资源，以便每个 Worker 都可以独立于其他 Worker 进行操作 -> 声明/定义一个创建类实例的函数, 初始化工人私有worker, 传输层链表
    ucs_class_t *cls = &uct_priv_worker_t_class -> typedef struct uct_priv_worker
    obj = ucs_class_malloc(cls)
    ucs_class_t *_cls = &uct_priv_worker_t_class
    uct_priv_worker_t_init -> static UCS_CLASS_INIT_FUNC(uct_priv_worker_t -> static UCS_CLASS_INIT_FUNC(uct_priv_worker_t -> 初始化父类以及当前类的传输链表
      static UCS_CLASS_INIT_FUNC(uct_worker_t)
        ucs_callbackq_init(&self->progress_q);
        ucs_vfs_obj_add_dir(NULL, self, "uct/worker/%p", self)
  status = dev_tl_lookup(&cmd_args, &if_info) -> 查找期望的传输层, 动态加载, 由最小延迟决定要使用的设备和传输, 实参为地址指针, 形参为指针
    status = uct_query_components(&components, &num_components) -> 查询组件列表。 获取当前系统上可用的传输组件列表, 得到8个组件, 为每个组件添加vfs对象:uct/component/组件名
      UCS_MODULE_FRAMEWORK_DECLARE(uct) -> 声明一个“框架”，它是可加载模块的特定集合的上下文。 通常特定框架中的模块提供相同内部接口的替代实现
        static ucs_init_once_t ucs_framework_init_once_uct = { { { 0, 0, 0, 0, 0, 0, 0, { 0, 0 } } }, 0 } -> 互斥锁+初始化标记
      UCS_MODULE_FRAMEWORK_LOAD(uct, 0) -> void ucs_load_modules 加载所有模块, self, tcp, sysv, posix, ib, rdmacm, cma, knem, ...
      [in] – _flags 模块加载标志，参见 ucs_module_load_flags_t 框架中的模块由 dlopen() 加载。 模块的共享库名称为：“lib<framework>_<module>.so.<version>”，其中： - <framework> 是框架名称 - <module> 是模块名称。 框架中所有模块的列表由自动生成的 config.h 文件中的预处理器宏 <framework>_MODULES 定义，例如：#define foo_MODULES ":bar1:bar2"。 - <version> 是模块的共享库版本，由 libtool 生成。 它是从当前库 (libucs) 的完整路径中提取的。 在以下位置搜索模块共享库（按优先级顺序）： 1. 当前共享库 (libucs) 目录内的“ucx”子目录 2. ${libdir}/ucx，其中 ${libdir} 是 库的安装目录 请注意，如果 libucs 是从其安装路径加载的，则 (1) 和 (2) 是同一位置。 仅当 libucs 被移动或从构建目录运行时，路径才会不同，在这种情况下，优先使用“本地库”而不是“已安装的”库。[in] – _name 框架名称（作为令牌）
        ucs_load_modules("uct", uct_MODULES, &ucs_framework_init_once_uct, 0) -> 加载框架, 模块
          ucs_module_loader_init_paths -> 找到路径, 然后动态加载: ucs_module_load_one(framework, module_name, flags) -> ucs_module_init(module_path, dl) -> 找到初始化方法名, 如: module_init_name, 动态打开模块: dl = dlopen(module_path, mode)
            fullpath = realpath(module_path, buffer)
            init_func = (init_func_t)ucs_module_dlsym_shallow module_init_name -> 找到全局初始化函数入口, 一般都没有
          modules_str = ucs_strdup(modules, "modules_list") -> 从内存跟踪表中查找字符串
          module_name = strtok_r(modules_str, ":", &saveptr) -> 每次取冒号分割的第一个字符串分段(字符串分割函数 strtok_r )
          ucs_module_loader_add_dl_dir
            动态库路径: 0x6070b0 "/home/xb/project/ucx/src/ucs/.libs/libucs.so.0"
            dladdr((void*)&ucs_module_loader_state, &dl_info) -> 利用dladdr来获得so自身的路径(ucs_module_loader_state)
            ucs_module_loader_state.srch_path[ucs_module_loader_state.srchpath_cnt++] = path -> 记录动态库位置
          ucs_module_loader_add_install_dir
          ucs_module_global_init -> 查找动态库入库函数地址: addr = dlsym(dl, symbol) -> status = init_func()
            void UCS_F_CTOR uct_ib_init()
              uct_component_register(&uct_ib_component) -> 注册组件
              uct_tl_register(&uct_ib_component, uct_ib_tls[i]) -> 注册所有IB传输层
      ucs_list_for_each uct_components_list 8个组件 -> ucs_vfs_obj_add_dir -> ucs_vfs_node_add 虚拟文件系统
    component_attr.md_resources = alloca -> alloca - 分配自动释放的内存
    status = uct_component_query(components[cmpt_index], &component_attr) -> 查询网卡, 拷贝内存域数据资源
      status = component->query_md_resources(component, &resources, &num_resources); -> uct_md_query_single_md_resource -> 调用每个组件的查询内存域资源接口
      UCS_MODULE_FRAMEWORK_LOAD(uct_ib, 0) -> 调用查询内存域资源接口中会加载对应的动态库
    status = uct_md_config_read(components[cmpt_index], NULL, NULL, &md_config); -> 读取内存域配置
      status = uct_config_read(&bundle, &component->md_config, env_prefix)
        status = ucs_config_parser_fill_opts(config_bundle->data, entry, full_prefix, 0)
          ucs_config_parser_set_default_values(opts, entry->table) -> ucs_config_sscanf_table
          ucs_config_parser_get_sub_prefix(env_prefix, &sub_prefix)
          ucs_config_parse_config_files()
          ucs_config_apply_config_vars -> 应用环境变量, 以及自定义前缀的环境变量
    for 迭代内存域资源
    uct_md_open -> 重要函数, 打开内存域
      status = component->md_open(component, md_name, config, &md) -> ucs_status_t uct_ib_md_open -> IB实现的内存域打开函数
        ib_device_list = ibv_get_device_list(&num_devices) -> 获取所有网卡列表, 获取设备列表, 比如4个网口(网卡设备), 可通过 ibdev2netdev 查询rdma网口映射
        ibv_fork_init -> 核心原理: 通过对所有已注册的MR所在内存页打MADV_DONTFORK标记，创建子进程后，MR所在内存页不会触发COW拷贝，避免了前面所说的COW带来网卡DMA内存地址不一致的问题, 但会引入额外的内存记录和查找开销(降低性能)
        status = uct_ib_ops[i]->ops->open(ib_device, md_config, &md) -> static ucs_status_t uct_ib_mlx5_devx_md_open
          vhca_id -> 虚拟主机通道适配器ID
          ctx = uct_ib_mlx5_devx_open_device(ibv_device) -> 通过创建完成队列和事件通道来检查网卡设备是否支持事件通道
            ctx = mlx5dv_open_device(ibv_device, &dv_attr) -> verbs_open_device -> rdma-core
            ibv_create_cq(ctx, 1, NULL, NULL, 0)
            ibv_destroy_cq(cq)
            event_channel = mlx5dv_devx_create_event_channel
            mlx5dv_devx_destroy_event_channel(event_channel)
          md = ucs_derived_of(uct_ib_md_alloc(sizeof(*md), "ib_mlx5_devx_md", ctx)
          status = uct_ib_mlx5_check_uar(md) -> 用户访问区域
            uct_ib_mlx5_devx_uar_init
              uct_ib_mlx5_devx_alloc_uar
                mlx5dv_devx_alloc_uar
            uct_ib_mlx5_devx_uar_cleanup
          md->mkey_tag = 0; -> 使用间接密钥使 MR 无效
          uct_ib_mlx5_devx_mr_lru_init(md)
          status = uct_ib_device_query(dev, ibv_device)
            uct_ib_query_device
              ibv_get_device_name
              ret = ibv_query_device_ex(ctx, NULL, attr)
                ret = vctx->query_device_ex(context, input, attr, sizeof(*attr))
            ibv_query_port
            ucs_topo_resolve_sysfs_path ->  "/sys/devices/pci0000:15/0000:15:04.0/0000:17:00.0" -> PCI地址
            ucs_topo_get_sysfs_dev
            uct_ib_device_set_pci_id
            ucs_topo_get_pci_bw -> 获取PCI带宽
              effective_bw = (p->bw_gbps * 1e9 / 8.0) * width * ((double)p->encoding / p->decoding) * link_utilization; -> 计算带宽
          ret = mlx5dv_devx_general_cmd(ctx, in, sizeof(in), out, sizeof(out)) -> ucs_status_t uct_ib_mlx5_devx_general_cmd -> rdma-core -> 通过 devx 接口发出通用命令, 介绍 DEVX 对象及其 DV API：创建/修改/读取/销毁。 还添加了 DEVX 通用命令 API，以便能够直接从固件读取 CAP, 参考: https://patchwork.kernel.org/project/linux-rdma/patch/1539190590-31186-2-git-send-email-yishaih@mellanox.com/
          status = uct_ib_mlx5_devx_query_lag(md, &lag_state) UCT_IB_MLX5_CMD_OP_QUERY_LAG -> 链路汇聚(bonding), 参考: https://docs.nvidia.com/networking/display/bluefielddpuosv385/link+aggregation
          md->port_select_mode = uct_ib_mlx5_devx_query_port_select(md)
            uct_ib_mlx5_devx_general_cmd UCT_IB_MLX5_CMD_OP_QUERY_LAG
          uct_ib_mlx5_is_xgvmi_alias_supported(ctx) -> 跨越GVMI (XGVMI) - DPU 可以代表主机常驻内存启动 RDMA 操作，仅当数据源自或目标为 DPU 内存时才涉及 DPU 内存, Guest VM ID 主机_虚机ID
          uct_ib_mlx5_devx_check_odp(md, md_config, cap) -> 按需分页 (ODP) 是一种可以缓解内存注册缺点的技术。 应用程序不再需要确定地址空间的底层物理页，并跟踪映射的有效性。 相反，当页面不存在时，HCA 向操作系统请求最新的转换，并且操作系统使由于不存在页面或映射更改而不再有效的转换无效。 ODP 不支持连续页。ODP 可以进一步分为 2 个子类：显式 ODP 和隐式 ODP。显式 ODP 在显式 ODP 中，应用程序仍然注册内存缓冲区以进行通信，但此操作用于定义 IO 的访问控制而不是 pin-down 页面。 ODP 内存区域 (MR) 在注册时不需要具有有效的映射。 隐式 ODP 在隐式 ODP 中，为应用程序提供了一个特殊的内存密钥，该密钥代表其完整的地址空间。 所有引用该键的 IO 访问（受限于与该键关联的访问权限）不需要注册任何虚拟地址范围。 有关 ODP 的更多信息，请参阅了解按需寻呼 (ODP) 社区帖子
          uct_ib_mlx5_devx_general_cmd
          dev->atomic_align = ucs_rounddown_pow2(arg_size) -> 向下取整对齐 
          uct_ib_md_open_common(&md->super, ibv_device, md_config) -> ucs_status_t uct_ib_md_open_common
            uct_ib_device_init -> 初始化IB设备
              uct_ib_device_get_locality -> 获取cpu位置top
              ucs_sys_fcntl_modfl O_NONBLOCK -> 设置fd为非阻塞模式
                oldfl = fcntl(fd, F_GETFL)
              ucs_async_set_event_handler uct_ib_async_event_handler -> 异步事件处理
                ucs_async_method_call(mode, add_event_fd, async, event_fd, events)       
                  ucs_async_thread_add_event_fd
                    ucs_async_thread_start(&thread)
                    ucs_event_set_add
                      epoll_ctl(event_set->event_fd, EPOLL_CTL_ADD, fd, &raw_event)
                    ucs_async_pipe_push(&thread->wakeup)
                      ret = write(p->write_fd, &dummy, sizeof(dummy)) -> 写0通知对端
            uct_ib_md_parse_subnet_prefix -> 添加UCT_IB_SUBNET_PREFIX=fe80::以按subnet_prefix过滤IB端口
            uct_ib_check_gpudirect_driver /sys/kernel/mm/memory_peers/nv_mem/version
            uct_ib_check_gpudirect_driver /dev/kfd
            uct_ib_md_check_dmabuf(md)                
              ibv_reg_dmabuf_mr(md->pd, 0, ucs_get_page_size(), 0, bad_fd, UCT_IB_MEM_ACCESS_FLAGS)
            uct_ib_md_set_pci_bw(md, md_config) -> 修复: PCI 速度和系统设备 ID 设置不正确, 先从系统获取, 没找到则从底层设备获取
          uct_ib_mlx5_md_port_counter_set_id_init(md)
            ucs_carray_for_each(counter_set_id, md->port_counter_set_ids, sizeof(md->port_counter_set_ids)) -> 遍历c语言数组
          ucs_mpool_params_reset(&mp_params) -> 重置内存池参数
          mp_params.ops             = &uct_ib_mlx5_dbrec_ops -> 设置池操作表
          ucs_mpool_init(&mp_params, &md->dbrec_pool)
            VALGRIND_CREATE_MEMPOOL(mp, 0, 0) -> valgrind内存池
          uct_ib_mlx5_md_buf_alloc(md, ucs_get_page_size(), 0, &md->zero_buf, &md->zero_mem, 0, "zero umem");
            先对齐内存
            madvise(buf, size, MADV_DONTFORK) -> MADV_DONTFORK 在执行fork(2)后，子进程不允许使用此范围的页面。这样是为了避免COW机制导致父进程在写入页面时更改页面的物理位置
            mlx5dv_devx_umem_reg(md->super.dev.ibv_context, buf, size, access_mode) -> 注册或取消注册由 devx 接口使用的用户内存。 寄存器动词公开 UMEM DEVX 对象，用于 DMA 的用户内存注册。 用于注册用户存储器的 API 将用户地址、长度和访问标志作为输入，并向用户提供一个对象作为输出，该对象保存由固件返回到该已注册存储器的 UMEM ID。 用户将在使用此内存而不是物理地址列表的设备直接命令中使用该 UMEM ID，例如在 mlx5dv_devx_obj_create 上创建 QP
          uct_ib_md_parse_relaxed_order(&md->super, md_config, ksm_atomic)
          uct_ib_mlx5_devx_init_flush_mr(md)
            uct_ib_reg_mr(&md->super, md->zero_buf, UCT_IB_MD_FLUSH_REMOTE_LENGTH, &params, UCT_IB_MEM_ACCESS_FLAGS, &md->flush_mr); -> 当 access_flags 包含 IBV_ACCESS_ON_DEMAND 时，ibv_reg_mr() 可能会失败并出现 EAGAIN。 这意味着预取由于与失效冲突而失败
              UCS_PROFILE_CALL_ALWAYS(ibv_reg_mr, md->pd, address, length, access_flags) -> 调用verbs接口注册内存
              ibv_reg_dmabuf_mr -> 注册内存的另一种方式
              uct_ib_md_print_mem_reg_err_msg -> 如果内存为空, 打印错误
                UCS_STRING_BUFFER_ONSTACK(msg, 256) -> 声明一个字符串缓冲区，该缓冲区使用现有字符串作为后备存储。 此类字符串缓冲区不会分配额外的内存，也不必进行清理，并且它还可以用于在作为函数参数传递的现有 C 字符串缓冲区上构建字符串。
                uct_ib_memlock_limit_msg(&msg, err)
                  ucs_sys_get_effective_memlock_rlimit
                    getrlimit(RLIMIT_MEMLOCK, &limit_info) -> 获取内存限制
                ucs_string_buffer_cstr(&msg)
                  c_str = ucs_array_begin(&strb->str) -> 返回字符串数组第一个元素
                    ((&strb->str)->buffer)
            uct_ib_mlx5_devx_reg_ksm_data_addr
              uct_ib_mlx5_alloc_mkey_inbox(list_size, &in)
              uct_ib_mlx5_devx_reg_ksm(md, atomic, iova, length, list_size -> UCT/IB/MLX5：内存注册流程部分重构，使用params struct进行多线程注册（从上层传递），使用params struct注册flush_mr，改进调试日志记录
                UCT_IB_MLX5DV_SET(create_mkey_in, in, opcode, UCT_IB_MLX5_CMD_OP_CREATE_MKEY) -> 往结构体中插入一个值
                mkc = UCT_IB_MLX5DV_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry) -> 限制所有条目的缓冲区大小以提高性能。 将密钥长度的虚拟地址 (KLM) 与固定内存大小关联时使用 KSM
                mlx5dv_devx_obj_create
        static ucs_status_t uct_self_md_open -> self模块实现的打开内存域
      uct_md_vfs_init(component, md, md_name) -> 用vfs节点表示组件和内存域
    uct_config_release(md_config)
    uct_md_query(iface_p->md, &iface_p->md_attr)
      status = uct_md_attr_v2_init(md, &md_attr_v2) -> static ucs_status_t uct_self_md_query -> ucs_status_t    uct_ib_md_query
        md_attr->access_mem_types          = UCS_BIT(UCS_MEMORY_TYPE_HOST) -> 内存访问的类型
        ucs_sys_cpuset_copy(&md_attr->local_cpus, &md->dev.local_cpus) -> for -> CPU_ISSET(c, src) -> 拷贝CPU参数
      uct_md_attr_from_v2(md_attr, &md_attr_v2) -> 用源(参数2)赋值给目的(参数1), 并用内存拷贝(memcpy)cpu和组件名
    uct_md_query_tl_resources(iface_p->md, &tl_resources, &num_tl_resources) -> 查询传输层资源。 该例程查询 uct_md_h“内存域”以获取可用的通信资源
        uct_self_query_tl_devices | uct_dc_mlx5_query_tl_devices
            uct_ib_device_query_ports
            uct_ib_device_port_check
                uct_ib_device_port_attr
        ucs_realloc
    for -> 遍历可用的传输层并找出合适的传输层名        
    status = init_iface(tl_resources[tl_index].dev_name, tl_resources[tl_index].tl_name, cmd_args->func_am_type, iface_p) -> 按传输层名初始化接口, 入参为: 网卡设备名,传输层名,活动消息类型, 接口
      status = uct_md_iface_config_read(iface_p->md, tl_name, NULL, NULL, &config) -> 读取并填充配置
      status = uct_iface_open(iface_p->md, iface_p->worker, &params, config, &iface_p->iface) -> 打开通信接口
        uct_find_tl(md->component, params->mode.device.tl_name) -> 查找传输层
        status = tl->iface_open -> static UCS_CLASS_DEFINE_NEW_FUNC(uct_rc_verbs_iface_t -> static UCS_CLASS_INIT_FUNC(uct_rc_verbs_iface_t <- .iface_open         = UCS_CLASS_NEW_FUNC_NAME(_iface_class) <- UCT_TL_DEFINE_ENTRY -> 宏展开得到(uct_rc_verbs_iface_t_new)
            init_attr.qp_type               = IBV_QPT_RC -> 设置QP属性
            UCS_CLASS_CALL_SUPER_INIT(uct_rc_iface_t -> 执行父类的构造函数(初始化) -> uct_rc_verbs_iface_t_init -> UCS_CLASS_INIT_FUNC(uct_rc_iface_t
                UCS_CLASS_CALL_SUPER_INIT(uct_ib_iface_t -> UCS_CLASS_INIT_FUNC(uct_ib_iface_t
                    preferred_cpu = ucs_cpu_set_find_lcs(&cpu_mask)
                    UCS_CLASS_CALL_SUPER_INIT(uct_base_iface_t
                        uct_base_iface_t_init (&self->super, _myclass->superclass, -> UCS_CLASS_INIT_FUNC(uct_base_iface_t
                            UCS_CLASS_CALL_SUPER_INIT(uct_iface_t, ops)
                                uct_iface_t_init (&self->super, _myclass->superclass -> UCS_CLASS_INIT_FUNC(uct_iface_t, uct_iface_ops_t *ops)
                                    self->ops = *ops;
                            UCT_CB_FLAGS_CHECK((params->field_mask
                            self->internal_ops      = internal_ops -> UCS_CLASS_INIT_FUNC(uct_base_iface_t, uct_iface_ops_t *ops,
                            uct_worker_progress_init(&self->prog)
                            uct_iface_set_stub_am_handler(self, id);
                                iface->am[id].cb    = uct_iface_stub_am_handler
                            UCS_STATS_NODE_ALLOC(&self->stats -> ucs_status_t ucs_stats_node_alloc
                                ucs_stats_node_new(cls, &node)
                                ucs_stats_node_initv(node, cls, name, ap)
                                    ucs_stats_name_check(cls->name)
                                    ucs_vsnprintf_safe(node->name, UCS_STAT_NAME_MAX, name, ap)
                                        vsnprintf(buf, size, fmt, ap)
                                        buf[size - 1] = '\0' -> 字符串数组补0
                                    ucs_list_head_init(&node->children[UCS_STATS_INACTIVE_CHILDREN])
                                ucs_stats_filter_node_new(node->cls, &filter_node)
                                ucs_stats_node_add(node, parent, filter_node)
                                    ucs_list_add_tail(&parent->children[UCS_STATS_ACTIVE_CHILDREN], &node->list)
                                    ucs_stats_add_to_filter(node, filter_node)
                    uct_ib_device_find_port(dev, params->mode.device.dev_name, &port_num)
                    uct_ib_iface_set_path_mtu(self, config)
                        (IBV_DEV_ATTR(dev, vendor_id) == 0x02c9) -> #  define IBV_DEV_ATTR(_dev, _attr)        ((_dev)->dev_attr._attr) -> 常用操作定义为宏
                    uct_ib_iface_init_pkey(self, config)
                        ibv_query_pkey(dev->ibv_context, iface->config.port_num, pkey_index, &port_pkey)
                        pkey = ntohs(port_pkey)
                    uct_ib_iface_init_gid_info(self, config)
                        uct_ib_iface_init_roce_gid_info(iface, cfg_gid_index)
                            uct_ib_device_select_gid(dev, port_num, &iface->gid_info) -> 选择要使用的最佳 gid 并在 RoCE 端口上设置其信息 - gid 索引、RoCE 版本和地址家族
                                uct_ib_device_query_gid_info
                                    ibv_query_gid(ctx, port_num, gid_index, &info->gid)
                                    uct_ib_device_get_addr_family(&info->gid, gid_index)
                                        const uint32_t addr_last_bits = raw->s6_addr32[2] ^ htonl(0x0000ffff)
                                        uct_ib_device_is_addr_ipv4_mcast(raw, addr_last_bits)
                                            return (raw->s6_addr32[0] == htonl(0xff0e0000)) && !(raw->s6_addr32[1] | addr_last_bits) -> 编码IPv4多播地址
                                uct_ib_device_test_roce_gid_index -> UCT/IB：使用 ibv_create_ah() 测试本地 gid 的有效性 在某些情况下，可能无法为 RoCE 设备正确配置网络地址，因此在选择要使用的默认 GID 索引时，我们希望跳过 GID 表中的条目 无法创建AH
                                    ibv_create_ah(ucs_container_of(dev, uct_ib_md_t, dev)->pd, &ah_attr)
                                    ibv_destroy_ah(ah)
                            或 uct_ib_device_query_gid_info
                        uct_ib_iface_init_roce_addr_prefix(iface, config)
                            ucs_sockaddr_inet_addr_size(gid_info->roce_info.addr_family, &addr_size)
                            uct_ib_device_get_roce_ndev_name
                            ucs_netif_get_addr -> 获取给定接口的地址和网络掩码
                            ucs_sockaddr_get_inet_addr
                            ucs_count_ptr_trailing_zero_bits -> 计算缓冲区末尾有多少位等于零
                            ucs_debug failed to detect RoCE subnet mask prefix on -> UCT：使用子网掩码确定 RoCE IP 的可达性
                        uct_ib_device_query_gid
                    uct_ib_iface_init_lmc(self, config)
                        uct_ib_iface_port_attr(iface)->lmc -> LID mask control 当多个LID被分配给当前端口时使用
                    uct_ib_iface_set_num_paths(self, config) -> UCT/IB：为 RoCE LAG(链路聚合,bond相关) 和 IB LMC 实现多路径
                        iface->num_paths = uct_ib_iface_roce_lag_level(iface) -> 计算bond后的实际带宽, 端口数
                            ucs_netif_bond_ad_num_ports(ndev_name) -> 获取绑定设备的活动 802.3ad 端口数。 如果设备不是绑定设备，或者未启用802.3ad，则返回1
                                ucs_read_file_number(&ad_num_ports, 1, "%s/%s", bond_path, UCS_BOND_NUM_PORTS_FILE); -> 
                        (uct_ib_iface_port_attr(iface)->active_speed == UCT_IB_SPEED_NDR))
                    self->comp_channel = ibv_create_comp_channel(dev->ibv_context) -> 支持中断通知
                    ucs_sys_fcntl_modfl(self->comp_channel->fd, O_NONBLOCK, 0) -> 设置事件通道fd为非阻塞模式
                    self->ops->create_cq(self, UCT_IB_DIR_TX -> ucs_status_t uct_ib_verbs_create_cq
                        ibv_cq_ex_to_cq(ibv_create_cq_ex(dev->ibv_context, &cq_attr))
                    self->ops->create_cq(self, UCT_IB_DIR_RX
                    self->addr_size  = uct_ib_iface_address_size(self) -> UCT/GTEST：CM 上的客户端-服务器 - 框架和 CM 基本功能。 重构 IB 地址函数，为在 qp-less 模式下通过 rdmacm 建立连接做准备，添加基本 gtest 来测试基本 CM（连接管理器）功能
                        return uct_ib_address_size(&params) -> 根据地址打包标记判断
                uct_iface_set_async_event_params(params, &self->async.event_cb,&self->async.event_arg)
                self->super.release_desc.cb = uct_ud_iface_release_desc -> 启用异步推进
                ucs_ptr_array_init(&self->eps, "ud_eps") -> 初始化数组, 先清空结构体字段, 然后设置数组名
                uct_ud_iface_create_qp(self, config) -> 创建队列对,设置类型(UD不可靠数据报), 
                    qp_init_attr.qp_type             = IBV_QPT_UD
                    ops->create_qp(&self->super, &qp_init_attr, &self->qp) -> ucs_status_t uct_ib_iface_create_qp
                        ibv_create_qp
                    qp_attr.qp_state   = IBV_QPS_INIT
                    ibv_modify_qp(self->qp, &qp_attr, IBV_QP_STATE | IBV_QP_PKEY_INDEX | IBV_QP_PORT | IBV_QP_QKEY)
                    qp_attr.qp_state = IBV_QPS_RTR
                    ibv_modify_qp(self->qp, &qp_attr, IBV_QP_STATE)
                    qp_attr.qp_state = IBV_QPS_RTS
                    ibv_modify_qp(self->qp, &qp_attr, IBV_QP_STATE | IBV_QP_SQ_PSN)
                uct_ib_iface_recv_mpool_init(&self->super, &config->super, params, "ud_recv_skb", &self->rx.mp) -> 创建接收描述符的内存池
                    grow = 1024
                    uct_iface_param_am_alignment(params, iface->config.seg_size, -> 根据接口参数中提供的用户配置初始化 AM 数据对齐及其偏移量
                        *align        = UCS_SYS_CACHE_LINE_SIZE -> cacheline 缓存行对齐
                    uct_iface_mpool_init uct_ib_iface_recv_desc_init
                        ucs_mpool_params_reset(&mp_params)
                        uct_iface_mpool_config_copy(&mp_params, config)
                        ucs_mpool_init(&mp_params, mp) -> ucs_status_t ucs_mpool_init
                            mp->data = ucs_malloc(sizeof(*mp->data) + params->priv_size, "mpool_data")
                            mp->data->grow_factor     = params->grow_factor -> 增长因子
                            VALGRIND_CREATE_MEMPOOL(mp, 0, 0); -> Memcheck：内存错误检测器, https://valgrind.org/docs/manual/mc-manual.html, 该请求将地址池注册为内存池的锚地址。 它还提供了 rzB 大小，指定放置在从池中分配的块周围的 redzone 应该有多大。 最后，它提供了一个 is_zeroed 参数，用于指定分配时池的块是否归零
                ucs_mpool_grow(&self->rx.mp, self->rx.available) -> UCT/IB：减少接收缓冲区的内存消耗。 仅当接口上启用进度时才分配接收缓冲区。 对于 UD 和 DC，分配少量接收缓冲区，以便能够处理新的传入连接, 给内存池增加指定数量的元素
                    data->ops->chunk_alloc(mp, &chunk_size, &ptr) -> UCS/UCT/TEST：重构和优化内存池基础设施 -> UCS_PROFILE_FUNC_ALWAYS(ucs_status_t, uct_iface_mp_chunk_alloc
                        uct_iface_mem_alloc(&iface->super, length, UCT_MD_MEM_ACCESS_LOCAL_READ  | UCT_MD_MEM_ACCESS_LOCAL_WRITE | UCT_MD_MEM_FLAG_LOCK, ucs_mpool_name(mp), &mem) -> 分配可用于零拷贝通信的内存。 分配可用于特定传输接口上的零复制数据传输或远程访问的内存区域
                            uct_md_query(iface->md, &md_attr)
                            params.mem_type        = UCS_MEMORY_TYPE_HOST
                            uct_mem_alloc(length, alloc_methods, num_alloc_methods, &params, mem) -> 为零拷贝通信和远程访问分配内存。 分配可能已注册的内存, 统一内存分配层?
                                uct_mem_alloc_check_params(length, methods, num_methods, params)
                                uct_md_mem_alloc(md, &alloc_length, &address,
                            uct_md_mem_reg(iface->md, mem->address, mem->length, flags,    
                    ucs_mpool_chunk_elems(mp, chunk)
                    ucs_mpool_num_elems_per_chunk(mp, chunk, chunk_size)
                    for (i = 0; i < chunk->num_elems; ++i)
                        ucs_mpool_add_to_freelist(mp, elem)
                            VALGRIND_MAKE_MEM_DEFINED(tail, sizeof *tail) -> UCS/MPOOL：在调试模式下添加 FIFO 行为选项，而不是 LIFO。FIFO 模式对于调试很有用，因为 mpool 对象不像 LIFO 那样被回收。 LIFO 的性能更好，因为它减少了缓存未命中和 mpool get/put 开销。 设置 UCS_MPOOL_FIFO=y 启用此模式
                    VALGRIND_MAKE_MEM_NOACCESS(chunk + 1, chunk_size - sizeof(*chunk))
                uct_iface_mpool_init(&self->super.super, &self->tx.mp,  uct_ud_iface_send_skb_init
            uct_rc_am_hdr_fill(&self->am_inl_hdr.rc_hdr, 0)
            status = uct_iface_mpool_init -> 创建地址控制器和原子内存池
            uct_rc_verbs_iface_init_inl_wrs -> 初始化可靠连接接口上的工作请求和内联请求,设置RDMA操作码
                iface->inl_am_wr.opcode         = IBV_WR_SEND;
                iface->inl_am_wr.send_flags     = IBV_SEND_INLINE;
                iface->inl_rwrite_wr.opcode     = IBV_WR_RDMA_WRITE;
                iface->inl_rwrite_wr.send_flags = IBV_SEND_SIGNALED | IBV_SEND_INLINE;
            status = uct_rc_init_fc_thresh(&config->super, &self->super)
            status = uct_rc_iface_qp_create
                UCS_PROFILE_CALL_ALWAYS(ibv_create_qp_ex, 或
                UCS_PROFILE_CALL_ALWAYS(ibv_create_qp
            uct_ib_destroy_qp(qp)
        ucs_vfs_obj_add_dir(worker, *iface_p, "iface/%p", *iface_p)
        ucs_vfs_obj_add_sym_link(*iface_p, md, "memory_domain")
        ucs_vfs_obj_set_dirty(*iface_p, uct_iface_vfs_refresh)
      uct_iface_progress_enable(iface_p->iface -> uct_base_iface_progress_enable_cb -> uct_rc_verbs_iface_common_progress_enable
        uct_rc_verbs_iface_common_prepost_recvs(iface)
          uct_rc_verbs_iface_post_recv_common
            uct_rc_verbs_iface_post_recv_always
              uct_ib_iface_prepare_rx_wrs
                UCT_TL_IFACE_GET_RX_DESC(&iface->super, mp, desc, break) -> ucs_mpool_get_inline
                  ucs_mpool_get_grow
                    ucs_mpool_grow -> chunk_alloc -> uct_iface_mp_chunk_alloc
                      uct_iface_mem_alloc
                    ...
                    ibv_reg_mr_iova2 -> 使用虚拟偏移地址注册内存区域, 参考RDMA内存注册: https://gwzlchn.github.io/202208/rdma-stack-02/#
              ibv_post_srq_recv  
      uct_rc_verbs_iface_progress(search) -> 驱动接口运转
        ucs_callbackq_add_safe
      status = uct_iface_query(iface_p->iface, &iface_p->iface_attr) -> uct_rc_verbs_iface_query
        status = uct_rc_iface_query
          status = uct_ib_iface_query -> ucs_status_t uct_ib_iface_query -> 可靠IB连接,接口属性查询
            static const uint8_t ib_port_widths[] = {[1] = 1, [2] = 4, [4] = 8, [8] = 12, [16] = 2};
            uct_base_iface_query(&iface->super, iface_attr)
                active_width = uct_ib_iface_port_attr(iface)->active_width -> 获取IB接口实际带宽
                switch (active_speed)
                    case UCT_IB_SPEED_EDR -> 网卡速度
                    iface_attr->latency.c = 600e-9
                    signal_rate           = 25.78125e9
                    encoding              = 64.0/66.0
            num_path   = uct_ib_iface_is_roce(iface) -> 计算线速(公式): Width(位宽) * SignalRate(速率) * Encoding(编码) * Num_paths(路径数量)
            extra_pkt_len = UCT_IB_BTH_LEN + xport_hdr_len +  UCT_IB_ICRC_LEN + UCT_IB_VCRC_LEN + UCT_IB_DELIM_LEN -> 计算包开销(额外的), 基本传输头(12字节) + CRC(4B) + VCRC(2B) + IB 线分隔符(2B)
            extra_pkt_len += UCT_IB_GRH_LEN + UCT_IB_ROCE_LEN -> 全局路由头(40B) + ROCE(14B)
            iface_attr->bandwidth.shared    = ucs_min((wire_speed * mtu) / (mtu + extra_pkt_len), md->pci_bw) -> 共享带宽计算公式, 与PCI带宽比较,取较小的值
          uct_ib_device_has_pci_atomics(dev))
        iface_attr->latency.m += 1e-9 -> 1ns 纳秒(每个附加QP)
        iface_attr->overhead   = 75e-9 -> 软件开销
        iface_attr->ep_addr_len = uct_ib_md_is_flush_rkey_valid
  status = uct_iface_set_am_handler(if_info.iface, id, hello_world, &cmd_args.func_am_type, 0) -> 设置服务端接收到客户端数据后的回调 -> static ucs_status_t hello_world
    iface->am[id].cb    = cb
  connect_common
    ret = getaddrinfo(server, service, &hints, &res)
    sockfd = socket(t->ai_family, t->ai_socktype, t->ai_protocol)
    setsockopt
    bind, listen, accept -> 等待客户端发起socket连接
  status = uct_iface_get_device_address(if_info.iface, own_dev)
  sendrecv(oob_sock, own_dev, if_info.iface_attr.device_addr_len, (void**)&peer_dev) -> 先通过socket发送和接收长度, 然后发送和接收地址, 交换地址
  uct_iface_is_reachable 检查地址是否可达 -> uct_ib_iface_is_reachable_v2 -> static int uct_ib_iface_dev_addr_is_reachable -> ucs_test_all_flags
    device_addr = (const uct_ib_address_t*) UCS_PARAM_VALUE -> 如果设置了字段掩码中的标志，则有条件地返回参数值。 否则，返回默认值
  status = uct_ep_create(&ep_params, &ep) -> 创建新端点 -> UCS_CLASS_DEFINE_NEW_FUNC(uct_rc_verbs_ep_t, uct_ep_t, const uct_ep_params_t *)
  ucs_vfs_obj_set_dirty(params->iface, uct_iface_vfs_refresh)
    ucs_vfs_global_init() -> UCS_INIT_ONCE(&ucs_vfs_init_once) 单例
    ucs_vfs_node_find_by_obj -> ucs_vfs_kh_find -> klib -> kh_get -> 独立且轻量级c库: https://github.com/attractivechaos/klib
  ucs_status_t uct_rc_verbs_ep_get_address
  status = uct_ep_connect_to_ep(ep, peer_dev, peer_ep) -> uct_rc_verbs_ep_connect_to_ep_v2
    status = uct_rc_iface_qp_connect(iface, ep->qp, qp_num, &ah_attr, path_mtu) -> ucs_status_t uct_rc_iface_qp_connect
      qp_attr.qp_state              = IBV_QPS_RTR -> 设备qp
      ret = ibv_modify_qp(qp, &qp_attr, qp_attr_mask); -> 设置qp状态机
      ...
      qp_attr.qp_state              = IBV_QPS_RTS
      ret = ibv_modify_qp(qp, &qp_attr, qp_attr_mask)
      ucs_debug("connected rc qp 0x%x on " -> 打印debug日志 -> connected rc qp 0x1a91b on mlx5_0:1/RoCE to lid 49152(+0) sl 0 remote_qp 0x1a91a mtu 1024 timer 18x7 rnr 13x7 rd_atom 16
  uct_worker_progress(if_info.worker) -> UCT 显示驱动工人推进。 该例程显式地处理任何未完成的通信操作和活动消息请求 -> uct_rc_verbs_iface_progress
    count = uct_rc_verbs_iface_poll_rx_common(iface) -> ibv_poll_cq
      uct_rc_verbs_iface_post_recv_common(iface, 0)
    return count + uct_rc_verbs_iface_poll_tx(iface) -> always_inline
      UCT_RC_VERBS_IFACE_FOREACH_TXWQE(&iface->super, i, wc, num_wcs) -> 遍历宏
      uct_rc_txqp_completion_desc
      ucs_arbiter_group_schedule -> 安排一个小组进行仲裁。 如果该组已经存在，则该操作将无效
        ucs_arbiter_schedule_head_if_not_scheduled(arbiter, head)
            ucs_list_add_tail(&arbiter->list, &head->list)
      uct_rc_verbs_update_tx_res(&iface->super, ep, count)
        uct_rc_txqp_available_add
        uct_rc_iface_update_reads -> 将 RDMA_READ 积分释放回 RC iface。 RDMA_READ 积分在完成回调中释放，但不会释放到 RC iface 以避免 OOO 发送。 否则，如果读取信用是唯一缺少的资源并在完成回调中释放，则即使挂起队列不为空，下一个完成回调也将能够发送
        uct_rc_iface_add_cq_credits -> UCT/IB：修复错误处理后清除待处理请求的问题
      ucs_arbiter_dispatch(&iface->super.tx.arbiter, 1, uct_rc_ep_process_pending, NULL) -> 在仲裁器中调度工作元素。 对于每个组，只要回调返回 REMOVE_ELEM 或 NEXT_GROUP，最多会调度 per_group 工作元素。 然后，对下一组执行相同的操作，直到仲裁器变空或回调返回 STOP。 如果一个组没有元素，或其回调返回 REMOVE_GROUP，则它将被删除，直到使用 ucs_arbiter_group_schedule() 将其放回到仲裁器上
        ucs_arbiter_dispatch_nonempty -> 仲裁器可以以循环方式安排组之间的工作，为每个组使用最少数量的内存
            ucs_arbiter_elem_init
  if (barrier(oob_sock, progress_worker, if_info.worker)) -> TCP/TEST：修复 ucp_hello_world 同时 ep close 的问题, UCP：当双方都关闭其 TCP 端点时，一方在尝试关闭刷新其端点时可以接收连接重置事件。 在这种情况下，我们不应该尝试调用用户错误回调。 相反，关闭操作应以 CONNECTION_RESET 状态完成。 UCT/TCP：出现错误时需要清除未完成的 PUT 操作。 测试：在多个传输上运行 ucp_hello_world。 目前，它仅在 docker 内运行时才使用 TCP，因此未检测到问题。 修复 hello_world 测试中的屏障以防止失败。
    send(oob_sock, &dummy, sizeof(dummy), 0)
    do while -> res = poll(&pfd, 1, 1)
    progress_cb(arg) -> progress_worker -> uct_worker_progress((uct_worker_h)arg) -> ...
    recv(oob_sock, &dummy, sizeof(dummy), MSG_WAITALL)
  out_free_ep -> 释放资源
  ...


server:
while (desc_holder == NULL) 
uct_worker_progress(if_info.worker) -> static inline unsigned ucs_callbackq_dispatch -> count += cb(elem->arg)
    static unsigned uct_rc_verbs_iface_progress(void *arg) <- self->super.progress
    count = uct_rc_verbs_iface_poll_rx_common(iface)
        uct_rc_verbs_iface_handle_am
        uct_iface_invoke_am
            status = handler->cb(handler->arg, data, length, flags) -> hello_world -> 服务端收到数据后回调
            print_strings("callback", func_am_t_str(func_am_type), data, length)
            ...





uct_iface_progress_enable
  uct_iface_progress -> return iface->ops.iface_progress(iface)
    uct_rc_iface_do_progress <- .iface_progress
      return iface->progress(iface)
      



typedef struct ucs_mpmc_queue, 多生产者多消费者线程安全队列。 在“良好”场景中，每次推/拉都是一个原子操作

typedef struct uct_tl_resource_desc, 通信资源描述符。 资源描述符是表示网络资源的对象。 资源描述符可以表示独立的通信资源（例如HCA端口、网络接口）或多个资源（例如多个网络接口或通信端口）。 它还可以表示通过单个物理网络接口定义的虚拟通信资源

md_resources, 内存域资源数组。 使用时，应在使用指向数组的指针调用 @ref uct_component_query 之前对其进行初始化，该数组足够大以容纳所有内存域资源条目。 调用后，该数组将填充现有内存域资源的信息。 为了分配该数组，您可以调用@ref uct_component_query两次：第一次将仅通过在field_mask中指定@ref UCT_COMPONENT_ATTR_FIELD_MD_RESOURCE_COUNT来获取所需的条目数量。 然后，可以为数组分配返回的条目数，并传递给对 @ref uct_component_query 的第二次调用，这次将 field_mask 设置为 @ref UCT_COMPONENT_ATTR_FIELD_MD_RESOURCES



connect_common
uct_iface_get_device_address
sendrecv
status = uct_ep_create(&ep_params, &ep)
uct_rc_verbs_ep_connect_to_ep_v2




client: 客户端流程
[root@node63 ucx]# /home/xb/project/ucx/examples/.libs/lt-uct_hello_world -d mlx5_0:1 -t rc_verbs -n 172.17.29.63 -z
...
if (connect(sockfd, t->ai_addr, t->ai_addrlen) == 0)

examples/uct_hello_world.c -> int main(int argc, char **argv)
if (parse_cmd(argc, argv, &cmd_args)) -> 解析命令行参数
ucs_async_context_create
uct_worker_create
dev_tl_lookup
status = uct_iface_set_am_handler(if_info.iface, id, hello_world -> 设置接收到数据后的回调
connect_common
uct_iface_get_device_address
uct_iface_get_address
uct_ep_create
sendrecv
char *str = (char *)mem_type_malloc(cmd_args.test_strlen) -> 分配16字节的字符(待发送的数据), malloc | cudaMalloc | cudaMallocManaged
generate_test_string -> 生成测试字符串
  memcpy(dst, src, count) -> 拷贝16字节的字符串到str
do_am_zcopy(&if_info, ep, id, &cmd_args, str) -> str -> char *buf 字符串地址转为buf地址
  uct_md_mem_reg -> uct_ib_mlx5_devx_mem_reg -> 将buf地址进行内存注册得到内存控制器(memh->address = address)
    uct_ib_memh_alloc(&md->super, length,
        memh = ucs_calloc(1, memh_base_size + (mr_size * num_mrs), "ib_memh")
    uct_ib_mlx5_devx_reg_mr(md, memh, address,
        access_flags & IBV_ACCESS_ON_DEMAND -> 按需注册
        uct_ib_reg_mr(&md->super, address, length, params, access_flags,
        *lkey_p = memh->mrs[mr_type].super.ib->lkey
        *rkey_p = memh->mrs[mr_type].super.ib->rkey
        uct_ib_mem_prefetch(&md->super, &memh->super, address, length) -> 支持内存预取
            UCS_PROFILE_CALL(ibv_advise_mr -> 提供有关 MR 中地址范围的建议
    mr = UCS_PROFILE_CALL_ALWAYS(ibv_reg_mr, md->pd, address, length, access_flags) -> 注册该段内存
  iov.buffer = buf -> buf转iov
  iov.memh   = memh -> 空指针
  iov.stride = 0;
  iov.count  = 1;
  ...
if (barrier(oob_sock, progress_worker, if_info.worker))

...
ucs_status_t do_am_short
  UCT_INLINE_API ucs_status_t uct_ep_am_short
    ucs_status_t uct_rc_verbs_ep_am_short
      uct_rc_verbs_iface_fill_inl_am_sge
      uct_rc_verbs_ep_post_send
        ibv_post_send



(gdb) b ibv_create_qp
#0  0x00007ffff65347b0 in ibv_create_qp () from /lib64/libibverbs.so.1
#1  0x00007ffff6778a58 in uct_rc_verbs_can_create_qp (ctx=<optimized out>, pd=0x60d3f0) at rc/verbs/rc_verbs_iface.c:556
#2  0x00007ffff6778c23 in uct_rc_verbs_query_tl_devices (md=0x60efd0, tl_devices_p=0x7fffffffd630, num_tl_devices_p=0x7fffffffd620) at rc/verbs/rc_verbs_iface.c:581
#3  0x00007ffff792864f in uct_md_query_tl_resources (md=0x60efd0, resources_p=resources_p@entry=0x7fffffffd7b0, num_resources_p=num_resources_p@entry=0x7fffffffd790) at base/uct_md.c:94
#4  0x000000000040248c in dev_tl_lookup (cmd_args=cmd_args@entry=0x7fffffffda00, iface_p=iface_p@entry=0x7fffffffdac0) at uct_hello_world.c:363
#5  0x000000000040193b in main (argc=<optimized out>, argv=<optimized out>) at uct_hello_world.c:611
(gdb) c
(gdb) bt
#0  0x00007ffff65347b0 in ibv_create_qp () from /lib64/libibverbs.so.1
#1  0x00007ffff675db21 in ibv_create_qp_ex (qp_init_attr_ex=0x7fffffffd558, context=<optimized out>) at /usr/include/infiniband/verbs.h:3016
#2  uct_ib_iface_create_qp (iface=iface@entry=0x6160f0, attr=attr@entry=0x7fffffffd520, qp_p=qp_p@entry=0x7fffffffd4e0) at base/ib_iface.c:1024
#3  0x00007ffff677238b in uct_rc_iface_qp_create (iface=iface@entry=0x6160f0, qp_p=qp_p@entry=0x7fffffffd4e0, attr=attr@entry=0x7fffffffd520, max_send_wr=<optimized out>, srq=<optimized out>)
    at rc/base/rc_iface.c:838
#4  0x00007ffff67794ed in uct_rc_verbs_iface_t_init (tl_config=0x60e130, params=<optimized out>, worker=<optimized out>, tl_md=<optimized out>, _init_count=0x7fffffffd4d0, 
    _myclass=0x7ffff69fc760 <uct_rc_verbs_iface_t_class>, self=0x6160f0) at rc/verbs/rc_verbs_iface.c:357
#5  uct_rc_verbs_iface_t_new (arg0=<optimized out>, arg1=<optimized out>, arg2=<optimized out>, arg3=0x60e130, obj_p=0x7fffffffdcd8) at rc/verbs/rc_verbs_iface.c:461
#6  0x00007ffff7928b5b in uct_iface_open (md=0x60efd0, worker=0x607560, params=params@entry=0x7fffffffd820, config=0x60e130, iface_p=iface_p@entry=0x7fffffffdcd8) at base/uct_md.c:250
#7  0x0000000000402738 in init_iface (iface_p=0x7fffffffdac0, func_am_type=FUNC_AM_SHORT, tl_name=0x616010 "rc_verbs", dev_name=0x61601a "mlx5_0:1") at uct_hello_world.c:271
#8  dev_tl_lookup (cmd_args=cmd_args@entry=0x7fffffffda00, iface_p=iface_p@entry=0x7fffffffdac0) at uct_hello_world.c:383
#9  0x000000000040193b in main (argc=<optimized out>, argv=<optimized out>) at uct_hello_world.c:611


利用宏, 注册传输层:
UCT_TL_DEFINE_ENTRY(&uct_ib_component, rc_verbs, uct_rc_verbs_query_tl_devices,
                    uct_rc_verbs_iface_t, "RC_VERBS_",
                    uct_rc_verbs_iface_config_table,
                    uct_rc_verbs_iface_config_t);

UCT_TL_DEFINE_ENTRY(&uct_tcp_component, tcp, uct_tcp_query_devices,


已注册的传输层类型, 搜索关键字(UCT_TL_DEFINE_ENTRY)
uct_tl_t uct_rc_verbs_tl = { .name = "rc_verbs", .query_devices = uct_rc_verbs_query_tl_devices, .iface_open = uct_rc_verbs_iface_t_new, .config = { .name = "rc_verbs"" transport", .prefix = "RC_VERBS_", .table = uct_rc_verbs_iface_config_table, .size = sizeof(uct_rc_verbs_iface_config_t), } };


rc_verbs
ud_mlx5
ud_verbs
cma
knem
self
tcp



网卡,传输层操作, uct_rc_verbs_iface_tl_ops


创建完成队列:
#0  0x00007ffff65345c0 in ibv_create_cq () from /lib64/libibverbs.so.1
#1  0x00007ffff67694dc in uct_ib_mlx5_devx_open_device (ibv_device=ibv_device@entry=0x60de40) at mlx5/dv/ib_mlx5dv_md.c:947
#2  0x00007ffff676cfd8 in uct_ib_mlx5_devx_md_open (ibv_device=0x60de40, md_config=0x607750, p_md=0x7fffffffd5e0) at mlx5/dv/ib_mlx5dv_md.c:1111
#3  0x00007ffff6760d04 in uct_ib_md_open (component=<optimized out>, md_name=0x7fffffffd680 "mlx5_0", uct_md_config=0x607750, md_p=0x7fffffffd640) at base/ib_md.c:1051
#4  0x00007ffff792852d in uct_md_open (component=0x7ffff69faf40 <uct_ib_component>, md_name=0x7fffffffd680 "mlx5_0", config=<optimized out>, md_p=md_p@entry=0x7fffffffddc0) at base/uct_md.c:61
#5  0x0000000000402427 in dev_tl_lookup (cmd_args=cmd_args@entry=0x7fffffffda00, iface_p=iface_p@entry=0x7fffffffdac0) at uct_hello_world.c:352
#6  0x000000000040193b in main (argc=<optimized out>, argv=<optimized out>) at uct_hello_world.c:611

#0  0x00007ffff65345c0 in ibv_create_cq () from /lib64/libibverbs.so.1
#1  0x00007ffff6778a39 in uct_rc_verbs_can_create_qp (ctx=<optimized out>, pd=0x60d3f0) at rc/verbs/rc_verbs_iface.c:546
#2  0x00007ffff6778c23 in uct_rc_verbs_query_tl_devices (md=0x60efd0, tl_devices_p=0x7fffffffd630, num_tl_devices_p=0x7fffffffd620) at rc/verbs/rc_verbs_iface.c:581
#3  0x00007ffff792864f in uct_md_query_tl_resources (md=0x60efd0, resources_p=resources_p@entry=0x7fffffffd7b0, num_resources_p=num_resources_p@entry=0x7fffffffd790) at base/uct_md.c:94
#4  0x000000000040248c in dev_tl_lookup (cmd_args=cmd_args@entry=0x7fffffffda00, iface_p=iface_p@entry=0x7fffffffdac0) at uct_hello_world.c:363
#5  0x000000000040193b in main (argc=<optimized out>, argv=<optimized out>) at uct_hello_world.c:611

#0  0x00007ffff65347b0 in ibv_create_qp () from /lib64/libibverbs.so.1
#1  0x00007ffff675db21 in ibv_create_qp_ex (qp_init_attr_ex=0x7fffffffd558, context=<optimized out>) at /usr/include/infiniband/verbs.h:3016
#2  uct_ib_iface_create_qp (iface=iface@entry=0x6160f0, attr=attr@entry=0x7fffffffd520, qp_p=qp_p@entry=0x7fffffffd4e0) at base/ib_iface.c:1024
#3  0x00007ffff677238b in uct_rc_iface_qp_create (iface=iface@entry=0x6160f0, qp_p=qp_p@entry=0x7fffffffd4e0, attr=attr@entry=0x7fffffffd520, max_send_wr=<optimized out>, srq=<optimized out>)
    at rc/base/rc_iface.c:838
#4  0x00007ffff67794ed in uct_rc_verbs_iface_t_init (tl_config=0x60e130, params=<optimized out>, worker=<optimized out>, tl_md=<optimized out>, _init_count=0x7fffffffd4d0, 
    _myclass=0x7ffff69fc760 <uct_rc_verbs_iface_t_class>, self=0x6160f0) at rc/verbs/rc_verbs_iface.c:357
#5  uct_rc_verbs_iface_t_new (arg0=<optimized out>, arg1=<optimized out>, arg2=<optimized out>, arg3=0x60e130, obj_p=0x7fffffffdcd8) at rc/verbs/rc_verbs_iface.c:461
#6  0x00007ffff7928b5b in uct_iface_open (md=0x60efd0, worker=0x607560, params=params@entry=0x7fffffffd820, config=0x60e130, iface_p=iface_p@entry=0x7fffffffdcd8) at base/uct_md.c:250
#7  0x0000000000402738 in init_iface (iface_p=0x7fffffffdac0, func_am_type=FUNC_AM_SHORT, tl_name=0x616010 "rc_verbs", dev_name=0x61601a "mlx5_0:1") at uct_hello_world.c:271
#8  dev_tl_lookup (cmd_args=cmd_args@entry=0x7fffffffda00, iface_p=iface_p@entry=0x7fffffffdac0) at uct_hello_world.c:383
#9  0x000000000040193b in main (argc=<optimized out>, argv=<optimized out>) at uct_hello_world.c:611


help, 帮助, 选项, 参数:
[root@node63 ucx]# /home/xb/project/ucx/examples/.libs/lt-uct_hello_world -h
Usage: uct_hello_world [parameters]
UCT hello world client/server example utility

Parameters are:
  -i      Select "uct_ep_am_short" function to send the message (default) // 默认短消息
  -b      Select "uct_ep_am_bcopy" function to send the message // 缓冲区
  -z      Select "uct_ep_am_zcopy" function to send the message // 零拷贝
  -d        Select device name
  -t        Select transport layer
  -n <name> Set node name or IP address of the server (required for client and should be ignored for server)
  -p <port>     Set alternative server port (default:13337)
  -6            Use IPv6 address in data exchange
  -s <size>     Set test string length (default:16)
  -m <mem type> Memory type of messages
                host - system memory (default)
                cuda - NVIDIA GPU memory
                cuda-managed - NVIDIA GPU managed/unified memory

Example:
  Server: uct_hello_world -d eth0 -t tcp
  /home/xb/project/ucx/examples/.libs/lt-uct_hello_world -d mlx5_0:1 -t rc_verbs

  Client: uct_hello_world -d eth0 -t tcp -n localhost
  /home/xb/project/ucx/examples/.libs/lt-uct_hello_world -d mlx5_0:1 -t rc_verbs -n 172.17.29.63


typedef struct uct_iface_ops 传输接口操作，API 中公开的每个操作都必须出现在下表中，以允许使用自定义操作创建接口/端点
ep_fence, 端点栅栏, 

typedef struct uct_worker, 进程引擎和用于分配通信资源的域。 不同工人独立驱动


ucs_status_t uct_ep_create, 创建新端点。 以可用模式之一创建 UCT 端点： -# 未连接端点：如果 uct_ep_params 中不存在任何地址，则会创建一个未连接端点。 要建立到远程端点的连接，需要调用 uct_ep_connect_to_ep  使用此模式需要 uct_ep_params_t::iface 具有 UCT_IFACE_FLAG_CONNECT_TO_EP 功能标志。 可以通过 uct_iface_query 获取。 -# 连接到远程接口：如果设置了 uct_ep_params_t::dev_addr 和 uct_ep_params_t::iface_addr，这将建立一个连接到远程接口的端点。 这要求 uct_ep_params_t::iface 具有 UCT_IFACE_FLAG_CONNECT_TO_IFACE 功能标志。 可以通过uct_iface_query获取。 -# 连接到远程套接字地址：如果设置了 uct_ep_params_t::sockaddr，这将创建一个连接到远程套接字的端点。 这要求设置 uct_ep_params::cm 或 uct_ep_params::iface。 在后一种情况下，接口必须支持 UCT_IFACE_FLAG_CONNECT_TO_SOCKADDR 标志，可以通过调用 uct_iface_query 来检查该标志。

参数：
[in] – params 用户为 ep_p 定义的 uct_ep_params_t 配置。
[out] – ep_p 填充新端点的句柄。

返回：
UCS_OK 端点创建成功。 这并不能保证端点已连接到参数中定义的目的地； 如果失败，错误将报告给通过 uct_iface_params_t.err_handler 提供给 uct_iface_open 的接口错误处理回调。 ucs_status_t 定义的错误代码





flow:
接口(uct_iface) -----> 操作(uct_iface_ops_t)
端点(uct_ep_h) 中包含 iface_操作




conjunction 连接
typedef struct uct_ib_address IB网络地址

UCS_CLASS_DEFINE_NEW_FUNC(uct_rc_verbs_ep_t, uct_ep_t, const uct_ep_params_t *); 宏展开
ucs_status_t uct_rc_verbs_ep_t_new(const uct_ep_params_t * arg0,  uct_ep_t **obj_p) 
{ 
  ucs_status_t status; 
  *obj_p = ((void *)0); 
  status = ({ ucs_class_t *cls = &uct_rc_verbs_ep_t_class; ucs_status_t _status; void *obj; obj = ucs_class_malloc(cls); 
  if (obj != ((void *)0)) 
  { 
    _status = ({ ucs_class_t *_cls = &uct_rc_verbs_ep_t_class; 
    int _init_counter = 1; 
    ucs_status_t __status; 
    __status = uct_rc_verbs_ep_t_init((uct_rc_verbs_ep_t*)(obj), _cls, &_init_counter,arg0); 
    if (__status != UCS_OK) { 
      ucs_class_call_cleanup_chain(&uct_rc_verbs_ep_t_class, (obj), _init_counter); 
    } (__status); }); 
    if (_status == UCS_OK) { *(obj_p) = (__typeof__(*(obj_p)))obj; } else { ucs_class_free(obj); *(obj_p) = ((void *)0); } } else { _status = UCS_ERR_NO_MEMORY; *(obj_p) = ((void *)0); } (_status); }); ucs_class_check_new_func_result(status, *obj_p); return status; }


重要数据结构: 
基础数据结构: src/ucs/datastruct

异步上下文: ucs_async_context

struct uct_ib_iface_config  传输层IB接口配置, 继承父类接口配置,自己的发送和接收配置, 内联, IB流分类, MTU, 计数器等配置




日志级别: 
ucs_global_opts_table
export UCX_LOG_LEVEL=debug
export UCX_LOG_LEVEL=trace

        [no],          [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_DEBUG], [Highest log level])],
        [warn],        [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_WARN], [Highest log level])],
        [diag],        [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_DIAG], [Highest log level])],
        [info],        [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_INFO], [Highest log level])],
        [debug],       [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_DEBUG], [Highest log level])],
        [trace],       [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_TRACE], [Highest log level])],
        [trace_req],   [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_TRACE_REQ], [Highest log level])],
        [trace_data],  [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_TRACE_DATA], [Highest log level])],
        [trace_async], [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_TRACE_ASYNC], [Highest log level])],
        [trace_func],  [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_TRACE_FUNC], [Highest log level])],
        [trace_poll],  [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_TRACE_POLL], [Highest log level])],
                       [AC_DEFINE([UCS_MAX_LOG_LEVEL], [UCS_LOG_LEVEL_TRACE_POLL], [Highest log level])])

ucs_init
  ucs_global_opts_init
    status = ucs_config_parser_fill_opts(&ucs_global_opts, UCS_CONFIG_GET_TABLE(ucs_global_opts_read_only_table), UCS_DEFAULT_ENV_PREFIX, 1); -> 配置文件 , 全局只读配置表 -> static ucs_config_field_t ucs_global_opts_read_only_table[] 
    static ucs_config_field_t ucs_global_opts_table[] -> 全局选项表
      ucs_config_parse_config_file
        file = fopen(file_path, "r"); -> 读取配置文件
        "/home/xb/project/ucx/install-debug/etc/ucx" -> 优先查找路径
    ucs_vfs_obj_add_dir(NULL, &ucs_global_opts, "ucs/global_opts")
    ucs_vfs_obj_add_rw_file(&ucs_global_opts, ucs_vfs_read_log_level, ucs_vfs_write_log_level, NULL, 0, "log_level")


io示例: buildlib/pr/io_demo/az-stage-io-demo.yaml



uct_rc_verbs_iface_common_progress_enable


typedef struct uct_rc_verbs_txcnt {
    uint16_t       pi;      /* producer (post_send) count */  生产者提交计数
    uint16_t       ci;      /* consumer (ibv_poll_cq) completion count */ 消费者完成计数
} uct_rc_verbs_txcnt_t;


仲裁者:
/*
 *  A mechanism to arbitrate among groups of queued work elements, which attempts
 * to be "fair" with respect to the groups.
 *
 * - "Arbiter" - the top-level entity.
 * - "Element" - a single work element.
 * - "Group"   - queue of work elements which would be dispatched in-order
 *
 * The arbiter contains a double-linked list of the group head elements. The
 * next group head to be dispatched is the first entry in the list. Whenever a
 * group is rescheduled, it's moved to the tail of the list. At any point, a
 * group head can be removed from the "middle" of the list.
 *
 * The groups and elements are arranged like this:
 *  - every arbitrated element points to the group (head).
 *  - first element in the group points to previous and next group (list)
 *  - first element in the group points to the first element of next group (next_group).
 *  - all except last element point to the next element in same group, and the
 *    last one points to the first (next).
 *
 * Note:
 *  Every element holds 4 pointers. It could be done with 3 pointers, so that
 *  the pointer to the previous group is put instead of "next" pointer in the last
 *  element in the group, when it is put on the arbiter queue. However, it makes
 *  the code much more complicated.
 *
 *
 * Arbiter:
 *   +=============+
 *   | list        +
 *   +======+======+
 *   | next | prev |
 *   +==|===+===|==+
 *      |       +----------------------------------------------+
 *      |                                                      |
 *      +------+                                               |
 *             |                                               |
 *             |                                               |
 * Elements:   V                                               V
 *       +------------+          +------------+          +------------+
 *       | list       |<-------->| list       |<-------->| list       |
 *       +------------+          +------------+          +------------+
 *    +->| next       +---+   +->| next       +---+      + next       +
 *    |  +------------+   |   |  +------------+   |      +------------+
 *    |  | group      |   |   |  | group      |   |      | group      |
 *    |  +------------+   |   |  +------------+   |      +--------+---+
 *    |                   |   |                   |          ^    |
 *    |                   |   |                   |          |    |
 *    |  +------------+   |   |  +------------+   |          |    |
 *    |  | list       |<--+   |  | list       |<--+          |    |
 *    |  +------------+       |  +------------+              |    |
 *    +--+ next       +       +--+ next       |              |    |
 *       +------------+          +------------+              |    |
 *       | group      |          | group      |              |    |
 *       +---------+--+          +--------+---+              |    |
 *            ^    |                 ^    |                  |    |
 * Groups:    |    |                 |    |                  |    |
 *            |    |                 |    |                  |    |
 *     +------+    |          +------+    |           +------+    |
 *     | tail |<---+          | tail |<---+           | tail |<---+
 *     +------+               +------+                +------+
 *
 */

typedef struct ucs_arbiter        ucs_arbiter_t;

一种在排队的工作元素组之间进行仲裁的机制，它试图对组进行“公平”
- “仲裁者” - 顶级实体。
- “元素”   - 单个工作元素。
-“组”      -将按顺序分派的工作元素队列，仲裁器包含组头元素的双链表。 下一个要分派的组头是列表中的第一个条目。 每当重新安排一个组时，它就会移至列表的末尾。 在任何时候，都可以从列表的“中间”删除组头。
组和元素的排列如下：
  - 每个仲裁元素都指向该组（头）。
  - 组中的第一个元素指向上一个和下一个组（列表）
  - 组中的第一个元素指向下一个组 (next_group) 的第一个元素。
  - 除最后一个元素外的所有元素都指向同一组中的下一个元素，最后一个元素指向第一个（下一个）。
注意：每个元素有4个指针。 可以使用 3 个指针来完成，以便当将其放入仲裁器队列时，将指向前一组的指针而不是组中最后一个元素中的“下一个”指针放入。 但是，这使得代码变得更加复杂








创建工人的宏展开: 声明/定义一个创建类实例的函数
ucs_status_t uct_worker_create(ucs_async_context_t* arg0, ucs_thread_mode_t arg1,  uct_worker_t **obj_p) { 
  ucs_status_t status; 
  *obj_p = ((void *)0); 
  status = ({ ucs_class_t *cls = &uct_priv_worker_t_class; ucs_status_t _status; void *obj; obj = ucs_class_malloc(cls); 
  if (obj != ((void *)0)) { 
    _status = ({ ucs_class_t *_cls = &uct_priv_worker_t_class; int _init_counter = 1;
    ucs_status_t __status; 
    __status = uct_priv_worker_t_init((uct_priv_worker_t*)(obj), _cls, &_init_counter,arg0 , arg1); 
    if (__status != UCS_OK) { 
      ucs_class_call_cleanup_chain(&uct_priv_worker_t_class, (obj), _init_counter);
    } 
    (__status); }); 
    if (_status == UCS_OK) { *(obj_p) = (__typeof__(*(obj_p)))obj; } else { ucs_class_free(obj); *(obj_p) = ((void *)0); } } else { _status = UCS_ERR_NO_MEMORY; *(obj_p) = ((void *)0); } (_status); }); ucs_class_check_new_func_result(status, *obj_p); return status; }




常用宏(预处理器): src/ucs/sys/preprocessor.h
/* Convert token to string */
#define UCS_PP_QUOTE(x)                   # x

/* Expand macro token to the macro value */
#define UCS_PP_EXPAND(x)                  x

/* Paste two expanded tokens */
#define __UCS_TOKENPASTE_HELPER(x, y)     x ## y
#define UCS_PP_TOKENPASTE(x, y)           __UCS_TOKENPASTE_HELPER(x, y)

/* Paste three expanded tokens */
#define __UCS_TOKENPASTE3_HELPER(x, y, z) x ## y ## z
#define UCS_PP_TOKENPASTE3(x, y, z)       __UCS_TOKENPASTE3_HELPER(x, y, z)

/* Unique value generator */
#ifdef __COUNTER__
#  define UCS_PP_UNIQUE_ID __COUNTER__
#else
#  define UCS_PP_UNIQUE_ID __LINE__
#endif

/* Creating unique identifiers, used for macros */
#define UCS_PP_APPEND_UNIQUE_ID(x)        UCS_PP_TOKENPASTE(x, UCS_PP_UNIQUE_ID)

/* Convert to string */
#define _UCS_PP_MAKE_STRING(x)            #x
#define UCS_PP_MAKE_STRING(x)             _UCS_PP_MAKE_STRING(x)




面向对象:
struct uct_rc_iface {
    uct_ib_iface_t              super;

类: 
typedef struct ucs_class     ucs_class_t;
struct ucs_class {
    const char               *name;
    size_t                   size;
    ucs_class_t              *superclass;
    ucs_class_init_func_t    init;
    ucs_class_cleanup_func_t cleanup;
};

typedef struct uct_priv_worker {
    uct_worker_t           super;
    ucs_async_context_t    *async;
    ucs_thread_mode_t      thread_mode;
    ucs_list_link_t        tl_data;
} uct_priv_worker_t;


/**
 * IB port active speed. IB端口活动速度
 */
enum {
    UCT_IB_SPEED_SDR     = 1,   //单通道数据速率
    UCT_IB_SPEED_DDR     = 2,
    UCT_IB_SPEED_QDR     = 4,
    UCT_IB_SPEED_FDR10   = 8,
    UCT_IB_SPEED_FDR     = 16,
    UCT_IB_SPEED_EDR     = 32,
    UCT_IB_SPEED_HDR     = 64,
    UCT_IB_SPEED_NDR     = 128,
    UCT_IB_SPEED_LAST
};

线速计算：Width * SignalRate * Encoding * Num_paths

注册tl, 传输层, 通过宏展开实现, 取消注册
_dl_init_internal
void UCS_F_CTOR uct_init()
uct_self_init() -> UCT_SINGLE_TL_INIT(&uct_self_component, self,,,) -> 链表的初始化
   void uct_self_init(void) { {; uct_component_register(&uct_self_component);}; uct_tl_register(&uct_self_component, &uct_self_tl); }  
   void uct_self_cleanup(void) { uct_tl_unregister(&uct_self_tl); {uct_component_unregister(&uct_self_component); ;}; }
uct_tl_register
  ucs_list_add_tail(&component->tl_list, &tl->list)



所有IB传输层类型(tl):
static uct_tl_t *uct_ib_tls[] = {
#ifdef HAVE_TL_DC
    &UCT_TL_NAME(dc_mlx5),
#endif
#ifdef HAVE_TL_RC
    &UCT_TL_NAME(rc_verbs),
#endif
#if defined (HAVE_TL_RC) && defined (HAVE_MLX5_DV)
    &UCT_TL_NAME(rc_mlx5),
#endif
#ifdef HAVE_TL_UD
    &UCT_TL_NAME(ud_verbs),
#endif
#if defined (HAVE_TL_UD) && defined (HAVE_MLX5_HW_UD)
    &UCT_TL_NAME(ud_mlx5)
#endif
};


类: src/ucs/type/class.h


wireup, 连线


网络插件:
● ofi: Libfabric (OpenFabrics Interfaces)**
● portals4: Portals-based networks (uncommon)
● self: Process-loopback communications
● sm: Shared memory
● smcuda: CUDA-aware shared memory
● tcp: TCP
● uct: UCX**
● ugni: Cray uGNI (userspace Generic Network Interface)**
● usnic: Cisco usNIC (userspace NIC)



环境变量前缀与配置文件名:
#define UCS_DEFAULT_ENV_PREFIX "UCX_"
#define UCS_CONFIG_ARRAY_MAX   128
#define UCX_CONFIG_FILE_NAME   "ucx.conf"

全局选项配置:
ucs_global_opts_t ucs_global_opts = {
    .log_component         = {UCS_LOG_LEVEL_WARN, "UCX", "*"},
    .log_print_enable      = 0,
    .log_file              = "",
    .log_file_size         = SIZE_MAX,
    .log_file_rotate       = 0,
    .log_buffer_size       = 1024,
    .log_data_size         = 0,
    .mpool_fifo            = 0,
    .handle_errors         = UCS_BIT(UCS_HANDLE_ERROR_BACKTRACE),
    .error_signals         = { NULL, 0 },
    .error_mail_to         = "",
    .error_mail_footer     = "",
    .gdb_command           = "gdb",
    .debug_signo           = SIGHUP,
    .log_level_trigger     = UCS_LOG_LEVEL_FATAL,
    .warn_unused_env_vars  = 1,
    .enable_memtype_cache  = UCS_TRY,
    .async_signo           = SIGALRM,
    .stats_dest            = "",
    .tuning_path           = "",
    .memtrack_dest         = "",
    .memtrack_limit        = UCS_MEMUNITS_INF,
    .stats_trigger         = "exit",
    .profile_mode          = 0,
    .profile_file          = "",
    .stats_filter          = { NULL, 0 },
    .stats_format          = UCS_STATS_FULL,
    .topo_prio             = { NULL, 0 },
    .vfs_enable            = 1,
    .vfs_thread_affinity   = 0,
    .rcache_check_pfn      = 0,
    .module_dir            = UCX_MODULE_DIR, /* defined in Makefile.am */ 模块搜索路径
    .module_log_level      = UCS_LOG_LEVEL_TRACE,
    .modules               = { {NULL, 0}, UCS_CONFIG_ALLOW_LIST_ALLOW_ALL },
    .arch                  = UCS_ARCH_GLOBAL_OPTS_INITALIZER,
    .rcache_stat_min       = 0,
    .rcache_stat_max       = 0
};



类型定义头文件: src/uct/api/uct_def.h



struct uct_md_attr
Memory domain attributes
} uct_md_attr_v2_t;
内存域属性。 该结构定义了内存域的属性，其中包括可分配的最大内存、访问内存所需的凭据、指示 CPU 邻近度的 CPU 掩码以及指示可分配的内存类型 (CPU/CUDA/ROCM) 的位图。 检测到的、分配的、访问的以及可以返回 dmabuf 属性的内存类型



static ucs_status_t uct_ib_verbs_md_open
  uct_ib_device_query
    status = uct_ib_query_device(dev->ibv_context, &dev->dev_attr)
      ret = ibv_query_device(ctx, attr) -> 查询网卡信息




ibv_get_device_list



typedef struct {
    double     bw_gbps;       /* Link speed */ 双精度,浮点数
    uint16_t   payload;       /* Payload used to data transfer */
    uint16_t   tlp_overhead;  /* PHY + data link layer + header + CRC */
    uint16_t   ctrl_ratio;    /* Number of TLC before ACK */
    uint16_t   ctrl_overhead; /* Length of control TLP */
    uint16_t   encoding;      /* Number of encoded symbol bits */
    uint16_t   decoding;      /* Number of decoded symbol bits */
    const char *name;         /* Name of PCI generation */
} ucs_topo_pci_info_t;


传输层包封装
MSC8156 技术数据表 (MSC8156)。 详细介绍了信号、AC/DC 特性、时钟信号特性、封装和引脚排列以及电气设计...
https://www.nxp.com/products/processors-and-microcontrollers/additional-mpu-mcus-architectures/digital-signal-processors/high-performance-six-core-dsp:MSC8156
/*
 * - TLP (Transaction Layer Packet) overhead calculations (no ECRC):
 *   Gen1/2:
 *     Start   SeqNum   Hdr_64bit   LCRC   End
 *       1   +   2    +   16      +   4  +  1  = 24
 *
 *   Gen3/4:
 *     Start   SeqNum   Hdr_64bit   LCRC
 *       4   +   2    +   16      +   4  = 26
 *
 * - DLLP (Data Link Layer Packet) overhead calculations:
 *    - Control packet 8b ACK + 8b flow control
 *    - ACK/FC ratio: 1 per 4 TLPs
 *
 * References:
 * [1] https://www.xilinx.com/support/documentation/white_papers/wp350.pdf
 * [2] https://xdevs.com/doc/Standards/PCI/PCI_Express_Base_4.0_Rev0.3_February19-2014.pdf
 * [3] https://www.nxp.com/docs/en/application-note/AN3935.pdf
 */

MSC8156 基于采用 StarCore® 技术构建的业界最高性能 DSP 内核，专为当今无线宽带、医疗成像、航空航天、国防以及先进测试和测量市场的高性能应用的高级处理要求和功能而设计。 它提供更高的性能和节能，在高度集成的片上系统 (SoC) 中利用 45 nm 处理技术，提供相当于 6 GHz 单核设备的性能。 MSC8156 帮助设备制造商创建最终产品和服务，在更小的硬件占用空间中集成更多功能。

MSC8156 DSP 提供高水平的性能和集成度，结合了六个完全可编程的增强型 SC3850 DSP 内核，每个内核的运行速度高达 1 GHz。 MAPLE-B 加速器由 NXP® 开发并集成在片上，支持 Turbo 和 Viterbi 通道解码以及 DFT/iDFT 和 FFT/iFFT 算法的硬件加速。 基于 RISC 的高性能内部 QUICC Engine® 子系统支持多种网络协议，以保证数据包网络上的可靠数据传输，同时显着减轻 DSP 内核的处理负担。

MSC8156嵌入大容量内部存储器，支持多种先进的高速接口类型，包括两个RapidIO®接口、两个用于网络通信的千兆位以太网接口、一个PCI Express®控制器、两个用于高速、行业标准存储器接口的DDR控制器 和四个多通道TDM 接口。 MSC8156 通过与所有 MSC825x 和 MSC815x DSP 设备的引脚兼容性实现了高度的可扩展性。


接口能力:
iface_attr->cap.flags       = UCT_IFACE_FLAG_AM_BCOPY        |
                              UCT_IFACE_FLAG_AM_ZCOPY        |
                              UCT_IFACE_FLAG_PUT_BCOPY       |
                              UCT_IFACE_FLAG_PUT_ZCOPY       |
                              UCT_IFACE_FLAG_GET_BCOPY       |
                              UCT_IFACE_FLAG_GET_ZCOPY       |
                              UCT_IFACE_FLAG_PENDING         |
                              UCT_IFACE_FLAG_CONNECT_TO_EP   |
                              UCT_IFACE_FLAG_CB_SYNC;
iface_attr->cap.event_flags = UCT_IFACE_FLAG_EVENT_SEND_COMP |
                              UCT_IFACE_FLAG_EVENT_RECV      |
                              UCT_IFACE_FLAG_EVENT_FD;




三种数据发送模式(活动消息):
/* Send active message to remote endpoint */
if (cmd_args.func_am_type == FUNC_AM_SHORT) {
    status = do_am_short(&if_info, ep, id, &cmd_args, str);
} else if (cmd_args.func_am_type == FUNC_AM_BCOPY) {
    status = do_am_bcopy(&if_info, ep, id, &cmd_args, str);
} else if (cmd_args.func_am_type == FUNC_AM_ZCOPY) {
    status = do_am_zcopy(&if_info, ep, id, &cmd_args, str);
}

短消息, 缓存区, 零拷贝
case 'i':
    args->func_am_type = FUNC_AM_SHORT;
    break;
case 'b':
    args->func_am_type = FUNC_AM_BCOPY;
    break;
case 'z':
    args->func_am_type = FUNC_AM_ZCOPY;

#if 1 /* 抓火焰图时开启此选项,暂停程序 */
char  *env;
/* 通过环境变量控制执行逻辑 export FLAME_GRAPH=1 */
env = getenv("FLAME_GRAPH");
if (env) {
    char word[128];
    printf("%d, input:", getpid());
    scanf("%s", word);
    printf("your input:%s\n", word);
}
#endif    
火焰图:
cd /home/xb/fire/FlameGraph
perf record -e cpu-clock  --call-graph dwarf -p 4080036

perf script -i perf.data &> perf.unfold
./stackcollapse-perf.pl ./perf.unfold &> ../perf.folded
./flamegraph.pl ../perf.folded > ../perf.svg
mv ../perf.svg ../ucx_uct_client_am_short_flame_graph.svg 
cd /home/xb/fire/FlameGraph
sz -y ../ucx_uct_client_am_short_flame_graph.svg 


do_am_bcopy
  uct_ep_am_bcopy
    uct_rc_verbs_ep_am_bcopy
      UCT_RC_IFACE_GET_TX_AM_BCOPY_DESC
      ucs_mpool_get_inline
        status = uct_rc_verbs_ep_post_send_desc(ep, &wr, desc, send_flags | IBV_SEND_SOLICITED, UCT_IB_MAX_ZCOPY_LOG_SGE(&iface->super.super));
        UCT_RC_VERBS_FILL_DESC_WR(wr, desc) -> 将描述填充到工作请求, 新建sge与wr通过sgl关联
        uct_rc_verbs_ep_post_send(iface, ep, wr, send_flags, max_log_sge)
          ucs_assertv(ep->qp->state == IBV_QPS_RTS -> 队列对状态必须是准备发送
          uct_rc_iface_tx_moderation
          uct_rc_ep_fm
          uct_ib_log_post_send
          ret = ibv_post_send(ep->qp, wr, &bad_wr); -> 提交wr到qp的发送队列, 触发服务端收到消息后打印, print_strings
          uct_rc_verbs_txqp_posted -> 为DC(动态连接队列对 Dynamically Connected (DC) QPs)传输类型做准备, cq流控信用, 状态计数器等
        uct_rc_txqp_add_send_op_sn -> 提交发送后, 将io描述, 按序号sn插入outstanding队列, 因为在轮询完成时，我们可获得完成的数量（而不是基于完成的零索引）
          ucs_queue_push(&txqp->outstanding, &op->queue)


ucs_status_t do_am_zcopy -> 零拷贝
  uct_md_mem_reg -> uct_md_mem_reg_v2 -> md->ops->mem_reg -> UCS_PROFILE_CALL_ALWAYS(ibv_reg_mr -> 注册内存 -> 分析函数调用, 当 access_flags 包含 IBV_ACCESS_ON_DEMAND 时，ibv_reg_mr() 可能会失败并出现 EAGAIN。 这意味着预取由于与失效冲突而失败
    __ibv_reg_mr
  comp.uct_comp.func   = zcopy_completion_cb -> 完成回调
  do ... while (status == UCS_ERR_NO_RESOURCE) -> 没资源时退出循环 
  status = uct_ep_am_zcopy(ep, id, NULL, 0, &iov, 1, 0, (uct_completion_t *)&comp) -> ep->iface->ops.ep_am_zcopy
    ucs_status_t uct_rc_mlx5_ep_am_zcopy | ucs_status_t uct_rc_verbs_ep_am_zcopy -> 可靠连接verbs端点的活动消息零拷贝
      struct ibv_sge sge[UCT_IB_MAX_IOV];
      UCT_CHECK_IOV_SIZE -> 检查向量IO个数, 应该不超过网卡最大发送(SGE-1), 第一个sge给header使用
      UCT_RC_CHECK_AM_ZCOPY -> 检查零拷贝参数, 检查数据和长度
      UCT_RC_CHECK_RES_AND_FC -> 检查资源和流控参数
      UCT_RC_IFACE_GET_TX_AM_ZCOPY_DESC -> 从内存池获取发送端零拷贝内存描述 -> UCT/RC：使用恒定的标头大小，无论 TM 状态如何, 从内存池中获取一个描述符，告诉valgrind它已经定义了，如果内存池为空则返回错误
          UCT_RC_IFACE_GET_TX_DESC(_iface, _mp, _desc) -> _desc = ucs_mpool_get_inline(_mp)
          uct_rc_zcopy_desc_set_comp(_desc, _comp, _send_flags)
            desc->super.handler   = (uct_rc_send_handler_t)ucs_mpool_put -> 如果完成为空,则发送完成, 将内存放回池子
            desc->super.handler   = uct_rc_ep_am_zcopy_handler -> 完成不为空,设置回调
                uct_invoke_completion(desc->super.user_comp, UCS_OK) -> 调用发送完成
                    ucs_debug_get_symbol_name((void*)comp->func)
                    uct_completion_update_status(comp, status)
                    comp->func(comp) -> 执行完成回调
                ucs_mpool_put(desc)
            desc->super.user_comp = comp;
            *send_flags           = IBV_SEND_SIGNALED
          uct_rc_zcopy_desc_set_header((uct_rc_hdr_t*)(_desc + 1), _id, _header, _header_length)
      sge_cnt = uct_ib_verbs_sge_fill_iov(sge + 1, iov, iovcnt) -> 填充IO(将iov设置到sge上), 通过 uct_iov_t 中提供的数据填充 ibv_sge 数据结构 该函数避免复制零长度的 IOV
        sge[sge_it].addr   = (uintptr_t)(iov[iov_it].buffer) -> buffer地址转sge地址
        sge[sge_it].lkey = uct_ib_memh_get_lkey(iov[iov_it].memh) -> 设置本地键
      UCT_RC_VERBS_FILL_AM_ZCOPY_WR_IOV -> 准备工作请求wr, 将sge首地址和数量设置到wr, rdma操作码为发送(双边, IBV_WR_SEND)
        wr.sg_list = sge; wr.num_sge = (sge_cnt + 1); wr.opcode = (typeof(wr.opcode))IBV_WR_SEND;
      UCT_TL_EP_STAT_OP -> 统计发送状态
      uct_rc_verbs_ep_post_send_desc | status = uct_rc_mlx5_ep_zcopy_post(ep, MLX5_OPCODE_SEND, iov, iovcnt, 0ul, id, header, header_length, 0, 0, 0ul, 0, 0, MLX5_WQE_CTRL_SOLICITED, uct_rc_ep_send_op_completion_handler, 0, comp);
        ----------- rc_mlx5_iface 迈络思可靠连接接口的提交实现
        uct_rc_mlx5_txqp_dptr_post_iov
          uct_rc_mlx5_am_hdr_fill
          uct_ib_mlx5_inline_copy
          uct_rc_mlx5_common_post_send
            uct_ib_mlx5_post_send -> UCT/IB/MLX5：修复 TX WQ 溢出检查，当 WQE 恰好在 hw_ci+qp_length 结束时，当前检查失败，即使这是有效的情况，将溢出检查重构为特定断言并添加注释来解释它们，移动检查 函数到 C 文件，因为它不是快速路径
              num_bb  = ucs_div_round_up(wqe_size, MLX5_SEND_WQE_BB) -> 向上取大的
              uct_ib_mlx5_txwq_validate
              ucs_memory_cpu_store_fence -> 内存屏障 -> asm volatile(""::: "memory") -> 防止编译器重新排序指令
              *wq->dbrec = htonl(sw_pi += num_bb) -> 写门铃记录, volatile uint32_t           *dbrec;
              ucs_memory_bus_store_fence()
              ucs_likely uct_ib_mlx5_bf_copy
                uct_ib_mlx5_bf_copy_bb -> UCP/UCT/IB：修复UCT中的线程模式,当以“序列化”模式创建 IB 接口时，请确保刷新写入组合缓冲区，以避免在另一个线程使用同一 MMIO 寄存器时数据损坏
                  UCS_WORD_COPY(uint64_t, dst, uint64_t, src, MLX5_SEND_WQE_BB) -> UCT/IB：为 DM 字节复制循环解决无效的 GCC 矢量化问题 GCC 可以生成“movdqa”指令，该指令假定源缓冲区与 16 字节对齐，但是源缓冲区是由用户提供的，并且可能未对齐。 将源缓冲区类型声明为严格未对齐，以防止 GCC 进行无效矢量化
            uct_rc_txqp_posted
        uct_rc_txqp_add_send_comp op_flags | UCT_RC_IFACE_SEND_OP_FLAG_ZCOPY
            uct_rc_ep_send_op_set_iov
                uct_iov_to_iovec -> 通过 UCT IOV 数组中提供的数据填充 IOVEC 数据结构。 该函数避免复制长度为零的 IOV
                    UCS_PTR_BYTE_OFFSET -> ((void *)((intptr_t)(_ptr) + (intptr_t)(_offset))) -> 通过内存地址偏移找到指定的内存地址
            uct_rc_txqp_add_send_op_sn(txqp, op, sn)
      UCT_RC_UPDATE_FC -> 更新流控
  uct_worker_progress




io描述
typedef struct uct_iov {
    void     *buffer;   /**< Data buffer */
    size_t    length;   /**< Length of the payload in bytes */
    uct_mem_h memh;     /**< Local memory key descriptor for the data */
    size_t    stride;   /**< Stride between beginnings of payload elements in
                             the buffer in bytes */
    unsigned  count;    /**< Number of payload elements in the buffer */
} uct_iov_t;


内联文件:
noinst_HEADERS += \
	mlx5/ib_mlx5_log.h \
	mlx5/ib_mlx5.h \
	mlx5/ib_mlx5.inl \
	mlx5/dv/ib_mlx5_dv.h \
	mlx5/dv/ib_mlx5_ifc.h


extern "C" static inline ucs_status_t uct_ep_am_zcopy(uct_ep_h ep, uint8_t id, const void *header, unsigned int header_length, const uct_iov_t *iov, size_t iovcnt, unsigned int flags, uct_completion_t *comp)
发送活动消息，同时避免本地内存复制 ::uct_iov_t 结构的 iov 数组中的输入数据发送到远程端（“收集输出”）。 iov 中的缓冲区按数组顺序进行处理。 这意味着函数在继续执行 iov[1] 之前完成 iov[0]，依此类推

参数：
[in] – ep 目标端点句柄。
[in] – id 活动消息 ID。 必须在 0..UCT_AM_ID_MAX-1 范围内。
[in] – header 活动消息头。
[in] – header_length 活动消息头长度（以字节为单位）。
[in] – iov 指向 ::uct_iov_t 结构数组。 iov 指针必须是 ::uct_iov_t 结构数组的有效地址。 特定的结构指针必须是有效的地址。 不需要 NULL 终止的数组。
[in] – iovcnt iov data ::uct_iov_t 结构数组的大小。 如果 iovcnt 为零，则数据被视为空。 iovcnt 受 uct_iface_attr_cap_am_max_iov "uct_iface_attr::cap::am::max_iov" 限制。
[in] – flags 活动消息标志，请参阅 uct_msg_flags。
[in] – 由 ::uct_completion_t 定义的 comp 完成句柄。

返回：
UCS_OK 操作成功完成。 UCS_INPROGRESS 某些通信操作仍在进行中。 如果提供了非 NULL comp，它将在完成这些操作后更新。 UCS_ERR_NO_RESOURCE 由于缺少发送资源而无法启动操作

笔记：
如果操作返回 UCS_INPROGRESS，则在 comp 完成操作之前，不得修改 iov 数组指向的内存缓冲区。 标头可以被释放或更改


test, google, ut, 单元测试, uct, 
gtest_SOURCES
gtest_SOURCES = common/main.cc
test/gtest/uct


test/gtest/common/main.cc -> main
  InitGoogleTest
  watchdog_start
  set_log_level
  RUN_ALL_TESTS
  watchdog_stop
  analyze_test_results



static inline ucs_status_t uct_iface_flush(uct_iface_h iface, unsigned int flags, uct_completion_t *comp)
刷新接口上未完成的通信操作。 刷新此调用之前在接口上发出的所有未完成的通信。 操作在原点或目标处完成。 确切的完成语义取决于 flags 参数。

参数：
[in] – iface 用于刷新通信的接口。
[in] – flags 控制完成语义的标志（当前仅支持 UCT_FLUSH_FLAG_LOCAL）。
[inout] – comp 完成句柄，由 uct_completion_t 定义。 可以为 NULL，这意味着调用将返回接口的当前状态，并且在未完成通信的情况下不会生成完成。 如果它不为 NULL，则调用完成时完成计数器会减 1。 当计数器达到 0 时调用完成回调

返回：
UCS_OK - 没有剩余的未完成的通信。 UCS_INPROGRESS - 某些通信操作仍在进行中。 如果提供了非 NULL 'comp'，它将在完成这些操作后更新


同: uct_ep_am_zcopy
static inline ucs_status_t uct_ep_put_zcopy(uct_ep_h ep, const uct_iov_t *iov, size_t iovcnt, uint64_t remote_addr, uct_rkey_t rkey, uct_completion_t *comp)



状态码, 错误码:
UCS_S_PACKED ucs_status_t;
为了评估从某个错误中恢复所需的必要步骤，外部 API 可返回的所有错误代码均按永久受错误影响的最大实体进行分组。 每个组的范围介于其 UCS_ERR_FIRST_<name> 和 UCS_ERR_LAST_<name> 枚举值之间。 例如，与端点级错误相比，如果链接失败，则可能足以销毁（并可能替换）它


/**
 * A queue of callback to execute
 */
struct ucs_callbackq {
    /**
     * Array of fast-path element, the last is reserved as a sentinel to mark
     * array end.
     */
    ucs_callbackq_elem_t           fast_elems[UCS_CALLBACKQ_FAST_COUNT + 1];  // 快速路径元素数组，最后一个元素被保留作为标记数组结束的标记
    ...
};




结构体字段对齐
struct mlx5_wqe_ctrl_seg {
	__be32		opmod_idx_opcode;
	__be32		qpn_ds;
	uint8_t		signature;
	__be16		dci_stream_channel_id;
	uint8_t		fm_ce_se;
	__be32		imm;
} __attribute__((__packed__)) __attribute__((__aligned__(4)));



数学库: src/ucs/sys/math.h



底层免拷贝:
static UCS_F_ALWAYS_INLINE void uct_ib_mlx5_bf_copy_bb(void * restrict dst,
                                                       void * restrict src)
{
#if defined( __SSE4_2__)
    UCS_WORD_COPY(__m128i, dst, __m128i, src, MLX5_SEND_WQE_BB);
#elif defined(__ARM_NEON)
    UCS_WORD_COPY(int16x8_t, dst, int16x8_t, src, MLX5_SEND_WQE_BB);
#else /* NO SIMD support */
    UCS_WORD_COPY(uint64_t, dst, uint64_t, src, MLX5_SEND_WQE_BB);
#endif
}



可重入自旋锁
typedef struct ucs_recursive_spinlock {
    ucs_spinlock_t super;
    int            count;
    pthread_t      owner;
} ucs_recursive_spinlock_t;


类方法: 
UCS_CLASS_INIT_FUNC -> 初始化



UCT组件及方法: 包含查询内存域资源, 打开内存域, 连接管理, rkey解包, rkey访问, rkey释放, rkey比较, 内存域配置条目, 连接管理配置条目, 传输列表, 链接到全局组件列表的链表, 标记位, 内存域对应的vfs初始化方法
struct uct_component {
    const char                              name[UCT_COMPONENT_NAME_MAX]; /**< Component name */
    uct_component_query_md_resources_func_t query_md_resources; /**< Query memory domain resources method */
    uct_component_md_open_func_t            md_open;            /**< Memory domain open method */
    uct_component_cm_open_func_t            cm_open;            /**< Connection manager open method */
    uct_component_rkey_unpack_func_t        rkey_unpack;        /**< Remote key unpack method */
    uct_component_rkey_ptr_func_t           rkey_ptr;           /**< Remote key access pointer method */
    uct_component_rkey_release_func_t       rkey_release;       /**< Remote key release method */
    uct_component_rkey_compare_func_t       rkey_compare;       /**< Remote key comparison method */
    ucs_config_global_list_entry_t          md_config;          /**< MD configuration entry */
    ucs_config_global_list_entry_t          cm_config;          /**< CM configuration entry */
    ucs_list_link_t                         tl_list;            /**< List of transports */
    ucs_list_link_t                         list;               /**< Entry in global list of components */
    uint64_t                                flags;              /**< Flags as defined by
                                                                     UCT_COMPONENT_FLAG_xx */
    /**< Memory domain initialize VFS method */
    uct_component_md_vfs_init_func_t        md_vfs_init;
};



配置解析器实现的方法:
配置变量格式
name: <env_prefix><table_prefix><field_name>
 * Examples of full variable names:
 *   - UCS_CIB_RNDV_THRESH
 *   - UCS_IB_TX_MODERATION
 */
typedef struct ucs_config_parser {
    int                      (*read) (const char *buf, void *dest, const void *arg);
    int                      (*write)(char *buf, size_t max,
                                      const void *src, const void *arg);
    ucs_status_t             (*clone)(const void *src, void *dest, const void *arg);
    void                     (*release)(void *ptr, const void *arg);
    void                     (*help)(char *buf, size_t max, const void *arg);
    const void               *arg;
} ucs_config_parser_t;


定义模块: AC_DEFINE_UNQUOTED([uct_MODULES], ["${uct_modules}"], [UCT loadable modules])
通过编译配置, 拼接多个字符串, 最终得到uct模块字符串(:ib:rdmacm:cma:knem), uct_modules="${uct_modules}:ib" 

如果定义了共享库: #ifdef UCX_SHARED_LIB
注册模块: status = init_func()


动态模块名:
0x7fffffffb7b0 "/home/xb/project/ucx/src/ucs/.libs/ucx/libuct_ib.so.0"


定义结构和初始化:
static struct {
    ucs_init_once_t  init;
    char             module_ext[NAME_MAX];
    unsigned         srchpath_cnt;
    char             *srch_path[UCS_MODULE_SRCH_PATH_MAX];
} ucs_module_loader_state = {
    .init         = UCS_INIT_ONCE_INITIALIZER,
    .module_ext   = ".so", /* default extension */
    .srchpath_cnt = 0,
    .srch_path    = { NULL, NULL}
};


void UCS_F_CTOR ucs_init()
  ucs_modules_load
    UCS_MODULE_FRAMEWORK_LOAD(ucs, UCS_MODULE_LOAD_FLAG_GLOBAL)

xtor构造器(main前执行):
#define UCS_F_CTOR __attribute__((constructor))

顺序:
void UCS_F_CTOR ucm_init()
void UCS_F_CTOR ucs_init()
void UCS_F_CTOR uct_init()
void UCS_F_CTOR uct_ib_init()
UCS_F_CTOR void uct_rdmacm_init(void)

重命名后的构造器: UCS_STATIC_INIT
UCT_COMPONENT_REGISTER 注册组件



void UCS_F_CTOR ucm_init()
  ucm_init_log() -> ucm_log_hostname 获取主机名
  ucm_init_malloc_hook() -> ucs_recursive_spinlock_init -> 初始化可重入锁

void UCS_F_CTOR ucs_init()
  ucs_check_cpu_flags -> 检查cpu特性
  ucs_log_early_init -> 初始化日志,进程ID等
  ucs_global_opts_init -> 初始化全局配置选项, 获取配置文件路径, 填充配置文件等, 添加全局vfs节点(ucs/global_opts), vfs日志级别等
  ucs_init_ucm_opts -> 添加ucm全局配置表(内存对齐16, 日志级别为WARN等), 填充配置文件(包含环境变量,前缀为UCX_), 初始化ucs库(kh的hash表初始化, map初始化), 打开动态库: /home/xb/project/ucx/src/ucm/.libs/libucm.so.0, 为 aarch64 实现了 CUDA bistro 挂钩（以在此平台上启用内存缓存）
  ucs_memtype_cache_global_init -> 互斥锁初始化
  ucs_cpu_init -> 优化版本的memcpy, ucs_cpu_builtin_memcpy, 获取CPU提供者(ucs_cpu_vendor)
  ucs_log_init -> 日志格式化宏, 打开日志文件,fork进程间互斥锁处理
  ucs_stats_init -> 状态统计初始化, 链表初始化, 数据库等初始化
  ucs_memtrack_init -> 内存跟踪初始化
  ucs_debug_init -> 调试和信号堆栈(sigaltstack)初始化
  ucs_profile_init -> 初始化线程私有上下文,私有数据
  ucs_async_global_init -> 异步事件和定时器初始化
  ucs_numa_init -> numa距离hash表初始化
  ucs_topo_init -> 用总线id查找设备
  ucs_rand_seed_init -> tcp允许使用端口范围, 生成高低位的启动ID(3817213743958597775), 随机值, 进程id, 时间, 线程id, 版本等
  ucs_sys_get_lib_path -> 查找当前库 libucs.so.0 (多个路径下查找库)
  ucs_get_process_cmdline -> 打印当前cmdline
  ucs_modules_load -> 监控进程的虚拟文件系统初始化, 加载所有ucs模块
  


ucs全局配置选项:
ucm_global_config_t ucm_global_opts = {
    .log_level                  = UCS_LOG_LEVEL_WARN,
    .enable_events              = 1,
    .mmap_hook_mode             = UCM_DEFAULT_HOOK_MODE,
    .enable_malloc_hooks        = 1,
    .enable_malloc_reloc        = 0,
    .cuda_hook_modes            =
#if UCM_BISTRO_HOOKS
                                  UCS_BIT(UCM_MMAP_HOOK_BISTRO) |
#endif
                                  UCS_BIT(UCM_MMAP_HOOK_RELOC),
    .enable_dynamic_mmap_thresh = 1,
    .alloc_alignment            = 16,
    .dlopen_process_rpath       = 1,
    .bistro_force_far_jump      = 0,
};



UCM：修复由 ucp_set_event_handler() 引起的堆损坏
修复安装时测试 mmap 事件的 sbrk() 与程序中任何其他线程的 brk/sbrk() 之间的竞争，作为正常堆操作的一部分。 这种竞争会导致堆损坏和程序中止/段错误。 一般来说，我们不应该直接调用brk/sbrk()。修复方法：
1. 在库初始化期间初始化 bistro 挂钩。 这可以确保没有其他线程会读取错误的机器指令。
2. 仅当事件测试来自独占上下文 (1) 时，才从事件测试中调用 brk/sbrk()。 对于非独占情况，仅使用无效参数进行虚拟调用，这不应对其他线程产生副作用。
3. 为 brk() 创建单独的事件，以避免在实际调用 brk() 时模拟 sbrk() 事件。
4. 修复 brk() 系统调用以返回完整的 64 位值
void ucm_mmap_init() -> 
  ucm_prevent_dl_unload
  ucm_mmap_install
    ucm_mmap_events_to_native_events
    ucm_mmap_test_events_nolock
    ucs_mmap_install_reloc
    ucm_mmap_test_events_nolock
    ucm_bistro_patch -> bistro hooks for cuda
      ucm_bistro_create_restore_point
      return ucm_bistro_apply_patch_atomic(func_ptr, patch, patch_len);



cpu提供商:
typedef enum ucs_cpu_vendor {
    UCS_CPU_VENDOR_UNKNOWN,
    UCS_CPU_VENDOR_INTEL,
    UCS_CPU_VENDOR_AMD,
    UCS_CPU_VENDOR_GENERIC_ARM,
    UCS_CPU_VENDOR_GENERIC_PPC,
    UCS_CPU_VENDOR_FUJITSU_ARM,
    UCS_CPU_VENDOR_ZHAOXIN,
    UCS_CPU_VENDOR_GENERIC_RV64G,
    UCS_CPU_VENDOR_LAST
} ucs_cpu_vendor_t;


CPU缓存类型
/* CPU cache types */
typedef enum ucs_cpu_cache_type {
    UCS_CPU_CACHE_L1d, /**< L1 data cache */          数据缓存
    UCS_CPU_CACHE_L1i, /**< L1 instruction cache */   指令缓存
    UCS_CPU_CACHE_L2,  /**< L2 cache */
    UCS_CPU_CACHE_L3,  /**< L3 cache */
    UCS_CPU_CACHE_LAST
} ucs_cpu_cache_type_t;
struct { /* sysfs entries for system cache sizes */
    int         level;
    const char *type;
} const ucs_cpu_cache_sysfs_name[] = {
    [UCS_CPU_CACHE_L1d] = {.level = 1, .type = "Data"},
    [UCS_CPU_CACHE_L1i] = {.level = 1, .type = "Instruction"},
    [UCS_CPU_CACHE_L2]  = {.level = 2, .type = "Unified"},
    [UCS_CPU_CACHE_L3]  = {.level = 3, .type = "Unified"}
};


src/ucs/arch/cpu.c
static void ucs_sysfs_get_cache_size() -> 获取缓存大小
double ucs_cpu_get_memcpy_bw() -> 获取内存带宽
ucs_arch_get_cpu_model -> 获取cpu模式

带宽, k, m, g, t, p
#define UCS_KBYTE    (1ull << 10)
#define UCS_MBYTE    (1ull << 20)
#define UCS_GBYTE    (1ull << 30)
#define UCS_TBYTE    (1ull << 40)
#define UCS_PBYTE    (1ull << 50)


格式化语法:
#define UCS_LOG_TIME_FMT        "[%lu.%06lu]"
#define UCS_LOG_METADATA_FMT    "%17s:%-4u %-4s %-5s %*s"
#define UCS_LOG_PROC_DATA_FMT   "[%s:%-5d:%s]"

#define UCS_LOG_COMPACT_FMT     UCS_LOG_TIME_FMT " " UCS_LOG_PROC_DATA_FMT "  "


ucs_log_init
  ucs_open_output_stream
    output_stream = fopen(filename, "w")
    pthread_atfork(ucs_log_atfork_prepare, ucs_log_atfork_post, ucs_log_atfork_post); -> fork出子进程前, 在父进程先下刷日志 -> fflush(ucs_log_file), fsync(fileno(ucs_log_file))


ucs_stats_init -> 状态统计初始化
  ucs_stats_open_dest
  ucs_stats_node_init_root
    va_start(ap, name)
    ucs_stats_node_initv
    va_end(ap)
    ucs_stats_filter_node_init_root
  ucs_array_init_dynamic

ucs_memtrack_init -> 内存跟踪, 结构体: typedef struct ucs_memtrack_entry
UCS/TESTS：为其添加服务和测试。
* 添加常用服务（调试、数据类型、日志记录、统计、配置解析、数学、原子、平台、测试）
* 使用 Google Test 基础设施添加测试框架，并对这些服务进行单元测试
debugging, datatypes, logging, statistics, configuration parsing, math, atomics, platform, testing
  ucs_memtrack_vfs_init
    ucs_vfs_obj_add_dir -> ucs/memtrack
    ucs_vfs_obj_add_ro_file -> 在VFS中添加描述对象特征的只读文件。 如果 obj 为 NULL，则挂载目录将用作 rel_path 的基础
    
ucs_async_global_init
  ucs_async_method_call_all(init) -> UCS/ASYNC：修复信号模式下的死锁。在获取事件处理程序哈希锁之前，需要禁用信号。 否则，可以调用信号处理程序并尝试在同一线程持有锁时获取锁 - 这将导致死锁。 （更通用的方法是引入一组类似于内核的 spin_lock_irqsave/spin_lock_irqrestore 的锁定原语，但当前的修复更简单）
    ucs_async_signal_ops.init(); -> ucs_async_signal_global_init
    ucs_async_thread_spinlock_ops.init(); 
    ucs_async_thread_mutex_ops.init(); -> ucs_empty_function
    ucs_async_poll_ops.init(); -> ucs_empty_function


const char* ucs_get_process_cmdline() -> 打印当前的命令行
  ucs_read_file(cmdline, sizeof(cmdline), 1, "/proc/self/cmdline")



ucs_modules_load -> UCS/TOOLS/BUILD：基于 FUSE 的监控文件系统的基础设施 为虚拟监控文件系统添加构建脚本和初始文件，可用于检查 UCX 对象（协议、传输、数据结构）及其关系（表示为 fs 层次结构和符号链接）并尽可能在运行时修改设置。
- ucx_vfs 是一个守护进程，它跟踪每个用户的挂载点和进程状态，并在进程终止时负责清理。
- ucs/vfs/base/vfs_obj.{c,h} 是保持对象层次结构的数据结构（“模型”）
- ucs/vfs/fuse 正在为文件系统操作提供服务（“视图”）
- ucs/vfs/sock 添加了守护进程和 UCS 之间通信的便捷功能
  ucs_load_modules("ucs", ucs_MODULES, &ucs_framework_init_once_ucs, UCS_MODULE_LOAD_FLAG_GLOBAL)


格式化, 大页, 启动id, 进程状态等宏
/* Default huge page size is 2 MBytes */
#define UCS_DEFAULT_MEM_FREE       640000
#define UCS_PROCESS_SMAPS_FILE     "/proc/self/smaps"
#define UCS_PROCESS_NS_DIR         "/proc/self/ns"
#define UCS_PROCESS_BOOTID_FILE    "/proc/sys/kernel/random/boot_id"
#define UCS_PROCESS_BOOTID_FMT     "%x-%4hx-%4hx-%4hx-%2hhx%2hhx%2hhx%2hhx%2hhx%2hhx"
#define UCS_PROCCESS_STAT_FMT      "/proc/%d/stat"
#define UCS_PROCESS_NS_FIRST       0xF0000000U
#define UCS_PROCESS_NS_NET_DFLT    0xF0000080U


传输层组件:
.name               =



query_md_resources
.query_md_resources = uct_ib_query_md_resources,
  ibv_get_device_list -> 4块rdma网卡
  uct_ib_device_is_accessible(device_list[i])
    (stat(device_path, &st)
    (access(device_path, R_OK | W_OK) != 0)) -> 测试网卡是否能访问


IB传输层类型:
enum ibv_transport_type {
	IBV_TRANSPORT_UNKNOWN	= -1,
	IBV_TRANSPORT_IB	= 0,
	IBV_TRANSPORT_IWARP,
	IBV_TRANSPORT_USNIC,
	IBV_TRANSPORT_USNIC_UDP,
	IBV_TRANSPORT_UNSPECIFIED,



ib配置文件: static ucs_config_field_t uct_ib_md_config_table[]
typedef struct ucs_config_field {
    const char               *name;
    const char               *dfl_value;  // default默认值(dfl)
    const char               *doc;
    size_t                   offset;
    ucs_config_parser_t      parser;
} ucs_config_field_t;



打印配置文档, 说明
ucx_info -f
print_flags |= UCS_CONFIG_PRINT_CONFIG | UCS_CONFIG_PRINT_HEADER | UCS_CONFIG_PRINT_DOC
if (flags & UCS_CONFIG_PRINT_DOC)
  ucs_config_print_doc_line_by_line


ppn: 每个节点的进程
每节点, 每个进程 (PPN) 的带宽规范：f(ppn) = 专用 + 共享 / ppn，该结构指定了一个函数，该函数用作各种 UCT 操作的带宽估计的基础。 此信息可用于选择 UCT 操作的最佳性能组合
typedef struct uct_ppn_bandwidth {
    double                   dedicated; /**< Dedicated bandwidth, bytes/second */
    double                   shared;    /**< Shared bandwidth, bytes/second */
} uct_ppn_bandwidth_t;
bandwidth: 11.91/ppn + 0.00 MB/sec
           共享         专用


打印系统信息, 获取cpu型号
void print_sys_info(int print_opts)
{
    size_t size;

    if (print_opts & PRINT_SYS_INFO) {
        printf("# Timer frequency: %.3f MHz\n",
               ucs_get_cpu_clocks_per_sec() / 1e6);
        printf("# Timer accuracy: %.3f %%\n", measure_timer_accuracy() * 100);
        printf("# CPU vendor: %s\n",
               cpu_vendor_names[ucs_arch_get_cpu_vendor()]);
        printf("# CPU model: %s\n", cpu_model_names[ucs_arch_get_cpu_model()]);



IB内存域
typedef struct uct_ib_md
int                      relaxed_order;
UCT/IB：如果需要，默认启用 pci 宽松顺序


API详解:
ucs_status_t uct_md_open(uct_component_h component, const char *md_name, const uct_md_config_t *config, uct_md_h *md_p)
打开一个内存域。 打开特定的内存域。 所有通信和内存操作都在特定内存域的上下文中执行。 因此必须在通信资源之前创建它。

用法: 
status = uct_md_open(components[cmpt_index], component_attr.md_resources[md_index] md_name, md_config, &iface_p->md);

参数：
[in] – 组件 要在其上打开内存域的组件，从 uct_query_components 返回。
[in] – md_name 内存域名，从 * uct_component_query 返回。
[in] – config MD 配置选项。 应从 uct_md_config_read() 函数获取，或指向扩展 uct_md_config_t 的 MD 特定结构。
[out] – md_p 填充内存域的句柄。


ucs_derived_of
派生结构的地址。 它必须在偏移量 0 处有一个“超级”成员。注意：我们在这里使用内置的 offsetof，因为我们不能在常量表达式中使用 ucs_offsetof()


cppcheck-suppress autoVariables: 检查抑制自动变量
Suppress clang warning: 抑制告警


uct_ib_md_config_t IB内存域配置
devx支持
DevX库通过使用KABI机制实现从用户空间区域直接访问mlx5设备驱动程序。这里的主要目的是使用户空间驱动程序尽可能独立于内核，以便可以通过以下方式激活未来的设备功能和命令 内核更改最少甚至没有

重要概念
vhca_id 用于 vport rx 规则中的设备索引, 设备索引类似于 PF 索引，并且仅限于最大物理端口。 例如，在PF下创建的SF，设备索引就是PF设备索引。 使用 vhca_id 获取每个 vport 的固件索引，用于 vport rx 规则和 vport 对事件

用户访问区域（UAR），通过用户访问区域（UAR）机制实现多个进程对HCA HW的隔离、受保护、独立的直接访问。 UAR 是 PCI 地址空间的一部分，映射为从 CPU 直接访问 HCA。 UAR 由多个页面组成，每个页面包含控制 HCA 操作的寄存器。 UAR机制用于向HCA发送执行或控制请求。 HCA 使用它来加强不同进程之间的保护和隔离。 跨进程隔离和保护通过四个关键机制实现： 1. 主机SW将不同的UAR页面映射到不同的消费者，从而在不同的消费者访问HCA控制空间中的同一页面时强制隔离。 2. 每个控制对象都可以通过UAR页面来访问（控制）。 3. HCA 驱动程序在初始化（“打开”）对象时将 UAR 页面与控制对象相关联。 4. 在对对象执行控制操作之前，HCA 验证用于发布命令的 UAR 页面是否与该对象上下文中指定的页面相匹配。 通过将 WQE 发布到相应的工作 WQ、更新门铃记录（如果适用）以及写入与该工作 WQ 关联的 UAR 页面中的相应门铃寄存器，将操作传递给 HCA。 写入 HCA 的门铃寄存器进一步称为响铃门铃。 UAR中的DoorBell寄存器是蓝焰缓冲区的前2个DWORDS


UCT/IB/MLX5: Use mlx5dv_devx_general_cmd to query HCA 使用devx命令查询HCA
struct uct_ib_mlx5_query_hca_cap_out_bits

IB传输层mlx5通用查询网卡特性的hca命令(位)
fpga, 
struct uct_ib_mlx5_cmd_hca_cap_bits 
- 启用硬件 DCS 支持
- 添加了运行时配置以限制 DCI 流的使用
- 更新了 *post_op 例程以设置 DCI 流通道 ID
- 添加了读取 HCA 功能以获取最大 DCI 流数量


IB传输层mlx5操作码
enum {
    UCT_IB_MLX5_CMD_OP_QUERY_HCA_CAP           = 0x100,
    UCT_IB_MLX5_CMD_OP_CREATE_MKEY             = 0x200,
    UCT_IB_MLX5_CMD_OP_CREATE_CQ               = 0x400,
    UCT_IB_MLX5_CMD_OP_CREATE_QP               = 0x500,
    UCT_IB_MLX5_CMD_OP_RST2INIT_QP             = 0x502,
    UCT_IB_MLX5_CMD_OP_INIT2RTR_QP             = 0x503,
    UCT_IB_MLX5_CMD_OP_RTR2RTS_QP              = 0x504,
    UCT_IB_MLX5_CMD_OP_2ERR_QP                 = 0x507,
    UCT_IB_MLX5_CMD_OP_2RST_QP                 = 0x50a,
    UCT_IB_MLX5_CMD_OP_QUERY_QP                = 0x50b,
    UCT_IB_MLX5_CMD_OP_CREATE_RMP              = 0x90c,
    UCT_IB_MLX5_CMD_OP_CREATE_DCT              = 0x710,
    UCT_IB_MLX5_CMD_OP_DRAIN_DCT               = 0x712,
    UCT_IB_MLX5_CMD_OP_CREATE_XRQ              = 0x717,
    UCT_IB_MLX5_CMD_OP_SET_XRQ_DC_PARAMS_ENTRY = 0x726,
    UCT_IB_MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT = 0x762,
    UCT_IB_MLX5_CMD_OP_QUERY_LAG               = 0x842,
    UCT_IB_MLX5_CMD_OP_CREATE_GENERAL_OBJECT   = 0xa00,
    UCT_IB_MLX5_CMD_OP_MODIFY_GENERAL_OBJECT   = 0xa01,
    UCT_IB_MLX5_CMD_OP_QUERY_GENERAL_OBJECT    = 0xa02,
    UCT_IB_MLX5_CMD_OP_ALLOW_OTHER_VHCA_ACCESS = 0xb16
};


IB链路聚合配置
typedef enum {
    /* QP are associated with port affinity */
    UCT_IB_MLX5_LAG_QUEUE_AFFINITY = 0x0,
    /* packets go to egress port through FT */
    UCT_IB_MLX5_LAG_PORT_SELECT_FT = 0x1,
    /* FDB select packet flow egress port */
    UCT_IB_MLX5_LAG_MULTI_PORT_ESW = 0x2,
    UCT_IB_MLX5_LAG_INVALID_MODE   = 0xFF
} uct_ib_port_select_mode_t;


处理异步事件的线程线程函数(调用栈)
ucs_async_thread_start
ucs_pthread_create(&thread->thread_id, ucs_async_thread_func, thread, "async"); 
  static void *ucs_async_thread_func(void *arg)
    status = ucs_event_set_wait(thread->event_set ucs_async_thread_ev_handler
      event_set_handler(events[i].data.ptr, io_events, arg)
        status = ucs_async_dispatch_handlers(&fd, 1, events)
          ucs_async_handler_dispatch(handler, events)
            ucs_async_handler_invoke(handler, events)
              handler->cb(handler->id, events, handler->arg)
                uct_ib_async_event_handler 异步事件处理
                  ibv_get_async_event(dev->ibv_context, &ibevent)
                  uct_ib_handle_async_event(dev, &event) -> 处理异步事件
                    switch (event->event_type)
                    ...
                    UCS_STATS_UPDATE_COUNTER(dev->stats, UCT_IB_DEVICE_STAT_ASYNC_EVENT, +1)
                  ibv_ack_async_event(&ibevent)

IB事件:
enum ibv_event_type {
	IBV_EVENT_CQ_ERR,
	IBV_EVENT_QP_FATAL,
	IBV_EVENT_QP_REQ_ERR,
	IBV_EVENT_QP_ACCESS_ERR,
	IBV_EVENT_COMM_EST,
	IBV_EVENT_SQ_DRAINED,
	IBV_EVENT_PATH_MIG,
	IBV_EVENT_PATH_MIG_ERR,
	IBV_EVENT_DEVICE_FATAL,
	IBV_EVENT_PORT_ACTIVE,
	IBV_EVENT_PORT_ERR,
	IBV_EVENT_LID_CHANGE,
	IBV_EVENT_PKEY_CHANGE,
	IBV_EVENT_SM_CHANGE,
	IBV_EVENT_SRQ_ERR,
	IBV_EVENT_SRQ_LIMIT_REACHED,
	IBV_EVENT_QP_LAST_WQE_REACHED,
	IBV_EVENT_CLIENT_REREGISTER,
	IBV_EVENT_GID_CHANGE,
	IBV_EVENT_WQ_FATAL,
};


内存类型
typedef enum ucs_memory_type {
    UCS_MEMORY_TYPE_HOST,          /**< Default system memory */
    UCS_MEMORY_TYPE_CUDA,          /**< NVIDIA CUDA memory */
    UCS_MEMORY_TYPE_CUDA_MANAGED,  /**< NVIDIA CUDA managed (or unified) memory */
    UCS_MEMORY_TYPE_ROCM,          /**< AMD ROCM memory */
    UCS_MEMORY_TYPE_ROCM_MANAGED,  /**< AMD ROCM managed system memory */
    UCS_MEMORY_TYPE_LAST,
    UCS_MEMORY_TYPE_UNKNOWN = UCS_MEMORY_TYPE_LAST
} ucs_memory_type_t;


Memory domain capability flags 内存域功能标签
UCT_MD_FLAG_ALLOC         = UCS_BIT(0),
...



/*
 * Iterate over all elements of a C-array 遍历c语言数组
 */
#define ucs_carray_for_each(_elem, _array, _length) \
    for ((_elem) = (_array); (_elem) < ((_array) + (_length)); ++(_elem))



执行并分析函数: UCS_PROFILE_CALL_ALWAYS


UCS_ARRAY_ALLOC_ONSTACK
UCS_ARRAY_IDENTIFIER
字符串缓冲区 - 动态的以 NULL 结尾的字符缓冲区，可以根据需要增长。
/**
 * String buffer - a dynamic NULL-terminated character buffer which can grow
 * on demand.
 */
typedef struct ucs_string_buffer {
    ucs_array_t(string_buffer) str;
} ucs_string_buffer_t;



UCT/CONFIG：在UCT中使用配置解析基础设施。
* 配置将针对每个接口。 每个端点只有一个是不可扩展的，而且看起来我们可以避免每个上下文的配置。
* 用户必须通过调用 uct_iface_config_read() 创建配置对象，并可能稍后对其进行修改。 然后，将其传递给 uct_iface_open()。
* 定义 iface 配置的层次结构：tl、ib、rc、rm_mlx5。
* tl中添加max_short和max_bcopy配置。
* 添加 ucx_info 实用程序来打印默认配置。


无符号内部类型的最大值:
/* Maximum of unsigned integral types.  */
# define UINT8_MAX		(255)
# define UINT16_MAX		(65535)
# define UINT32_MAX		(4294967295U)
# define UINT64_MAX		(__UINT64_C(18446744073709551615))


初始化工人驱动/推进
void uct_worker_progress_init(uct_worker_progress_t *prog)
UCS/CBQ/UCT/API：整合慢速/快速 API 并使所有操作为 O(1)。
+ 使用单一 API 进行慢速/快速回调，元素将从内部数组分配，而不是由用户分配。
+ 使用唯一的整数 id 跟踪回调，这样删除回调的时间复杂度为 O(1)。
+ 通过确保已删除回调的“arg”始终指向回调q 本身，从回调调度函数中删除内存加载栅栏。 这样，就可以从另一个线程添加服务回调，而不会出现内存排序问题，因为仅更新单个回调指针。
这样，调度函数就可以内联在 API 中。
+ 通过首先将回调设置为慢速路径然后将其提升为快速路径来实现 add_safe。
+ 在callbackq 结构本身中保留较小的固定大小的快速路径回调，以减少内存取消引用。
+ 支持一次性慢速回调，在单次执行后自行删除。
+ 停止计算回调的引用，将其留给用户。
+ 删除“async”参数，并让用户负责在需要时阻止异步上下文


MTU
enum ibv_mtu {
	IBV_MTU_256  = 1,
	IBV_MTU_512  = 2,
	IBV_MTU_1024 = 3,
	IBV_MTU_2048 = 4,
	IBV_MTU_4096 = 5
};


端口状态
enum ibv_port_state {
	IBV_PORT_NOP		= 0,
	IBV_PORT_DOWN		= 1,
	IBV_PORT_INIT		= 2,
	IBV_PORT_ARMED		= 3,
	IBV_PORT_ACTIVE		= 4,
	IBV_PORT_ACTIVE_DEFER	= 5
};

链路
enum {
	IBV_LINK_LAYER_UNSPECIFIED,
	IBV_LINK_LAYER_INFINIBAND,
	IBV_LINK_LAYER_ETHERNET,
};


端口能力
enum ibv_port_cap_flags {
	IBV_PORT_SM				= 1 <<  1,
	IBV_PORT_NOTICE_SUP			= 1 <<  2,
	IBV_PORT_TRAP_SUP			= 1 <<  3,
	IBV_PORT_OPT_IPD_SUP			= 1 <<  4,
	IBV_PORT_AUTO_MIGR_SUP			= 1 <<  5,
	IBV_PORT_SL_MAP_SUP			= 1 <<  6,
	IBV_PORT_MKEY_NVRAM			= 1 <<  7,
	IBV_PORT_PKEY_NVRAM			= 1 <<  8,
	IBV_PORT_LED_INFO_SUP			= 1 <<  9,
	IBV_PORT_SYS_IMAGE_GUID_SUP		= 1 << 11,
	IBV_PORT_PKEY_SW_EXT_PORT_TRAP_SUP	= 1 << 12,
	IBV_PORT_EXTENDED_SPEEDS_SUP		= 1 << 14,
	IBV_PORT_CAP_MASK2_SUP			= 1 << 15,
	IBV_PORT_CM_SUP				= 1 << 16,
	IBV_PORT_SNMP_TUNNEL_SUP		= 1 << 17,
	IBV_PORT_REINIT_SUP			= 1 << 18,
	IBV_PORT_DEVICE_MGMT_SUP		= 1 << 19,
	IBV_PORT_VENDOR_CLASS_SUP		= 1 << 20,
	IBV_PORT_DR_NOTICE_SUP			= 1 << 21,
	IBV_PORT_CAP_MASK_NOTICE_SUP		= 1 << 22,
	IBV_PORT_BOOT_MGMT_SUP			= 1 << 23,
	IBV_PORT_LINK_LATENCY_SUP		= 1 << 24,
	IBV_PORT_CLIENT_REG_SUP			= 1 << 25,
	IBV_PORT_IP_BASED_GIDS			= 1 << 26
};


roce版本
typedef enum uct_ib_roce_version {
    UCT_IB_DEVICE_ROCE_V1,
    UCT_IB_DEVICE_ROCE_V1_5,
    UCT_IB_DEVICE_ROCE_V2,
    UCT_IB_DEVICE_ROCE_ANY
} uct_ib_roce_version_t;


IB设备(网卡)支持的功能
enum {
    UCT_IB_DEVICE_FLAG_MLX4_PRM = UCS_BIT(1),   /* Device supports mlx4 PRM */
    UCT_IB_DEVICE_FLAG_MLX5_PRM = UCS_BIT(2),   /* Device supports mlx5 PRM */
    UCT_IB_DEVICE_FLAG_MELLANOX = UCS_BIT(3),   /* Mellanox device */
    UCT_IB_DEVICE_FLAG_LINK_IB  = UCS_BIT(5),   /* Require only IB */
    UCT_IB_DEVICE_FLAG_DC_V1    = UCS_BIT(6),   /* Device supports DC ver 1 */
    UCT_IB_DEVICE_FLAG_DC_V2    = UCS_BIT(7),   /* Device supports DC ver 2 */
    UCT_IB_DEVICE_FLAG_AV       = UCS_BIT(8),   /* Device supports compact AV */
    UCT_IB_DEVICE_FLAG_DC       = UCT_IB_DEVICE_FLAG_DC_V1 |
                                  UCT_IB_DEVICE_FLAG_DC_V2, /* Device supports DC */
    UCT_IB_DEVICE_FAILED        = UCS_BIT(9)    /* Got fatal error */
};



IB协议及RDMA相关参数
#define UCT_IB_QPN_ORDER                  24  /* How many bits can be an IB QP number */
#define UCT_IB_UIDX_SHIFT                 8   /* BE uidx shift */
#define UCT_IB_LRH_LEN                    8   /* IB Local routing header */
#define UCT_IB_GRH_LEN                    40  /* IB GLobal routing header */
#define UCT_IB_BTH_LEN                    12  /* IB base transport header */
#define UCT_IB_ROCE_LEN                   14  /* Ethernet header -
                                                 6B for Destination MAC +
                                                 6B for Source MAC + 2B Type (RoCE) */
#define UCT_IB_DETH_LEN                   8   /* IB datagram header */
#define UCT_IB_RETH_LEN                   16  /* IB RDMA header */
#define UCT_IB_ATOMIC_ETH_LEN             28  /* IB atomic header */
#define UCT_IB_AETH_LEN                   4   /* IB ack */
#define UCT_IB_PAYLOAD_ALIGN              4   /* IB payload padding */
#define UCT_IB_ICRC_LEN                   4   /* IB invariant crc footer */
#define UCT_IB_VCRC_LEN                   2   /* IB variant crc footer */
#define UCT_IB_DELIM_LEN                  2   /* IB wire delimiter */
#define UCT_IB_FDR_PACKET_GAP             64  /* Minimal FDR packet gap */
#define UCT_IB_MAX_MESSAGE_SIZE           (2UL << 30) /* Maximal IB message size */
#define UCT_IB_PKEY_PARTITION_MASK        0x7fff /* IB partition number mask */
#define UCT_IB_PKEY_MEMBERSHIP_MASK       0x8000 /* Full/send-only member */
#define UCT_IB_PKEY_DEFAULT               0xffff /* Default PKEY */
#define UCT_IB_FIRST_PORT                 1
#define UCT_IB_DEV_MAX_PORTS              2
#define UCT_IB_FABRIC_TIME_MAX            32
#define UCT_IB_INVALID_MKEY               0xffffffffu
#define UCT_IB_KEY                        0x1ee7a330
#define UCT_IB_LINK_LOCAL_PREFIX          be64toh(0xfe80000000000000ul) /* IBTA 4.1.1 12a */
#define UCT_IB_SITE_LOCAL_PREFIX          be64toh(0xfec0000000000000ul) /* IBTA 4.1.1 12b */
#define UCT_IB_SITE_LOCAL_MASK            be64toh(0xffffffffffff0000ul) /* IBTA 4.1.1 12b */
#define UCT_IB_DEFAULT_ROCEV2_DSCP        106  /* Default DSCP for RoCE v2 */
#define UCT_IB_ROCE_UDP_SRC_PORT_BASE     0xC000
#define UCT_IB_CQE_SL_PKTYPE_MASK         0x7 /* SL for IB or packet type
                                                 (GRH/IPv4/IPv6) for RoCE in the
                                                 CQE */
#define UCT_IB_DEVICE_SYSFS_PFX           "/sys/class/infiniband/%s"
#define UCT_IB_DEVICE_SYSFS_FMT           UCT_IB_DEVICE_SYSFS_PFX "/device/%s"
#define UCT_IB_DEVICE_SYSFS_GID_ATTR_PFX  UCT_IB_DEVICE_SYSFS_PFX "/ports/%d/gid_attrs"
#define UCT_IB_DEVICE_SYSFS_GID_TYPE_FMT  UCT_IB_DEVICE_SYSFS_GID_ATTR_PFX "/types/%d"
#define UCT_IB_DEVICE_SYSFS_GID_NDEV_FMT  UCT_IB_DEVICE_SYSFS_GID_ATTR_PFX "/ndevs/%d"
#define UCT_IB_DEVICE_ECE_DEFAULT         0x0         /* default ECE */
#define UCT_IB_DEVICE_ECE_MAX             0xffffffffU /* max ECE */




IB端口属性
struct ibv_port_attr {
	enum ibv_port_state	state;
	enum ibv_mtu		max_mtu;
	enum ibv_mtu		active_mtu;
	int			gid_tbl_len;
	uint32_t		port_cap_flags;
	uint32_t		max_msg_sz;
	uint32_t		bad_pkey_cntr;
	uint32_t		qkey_viol_cntr;
	uint16_t		pkey_tbl_len;
	uint16_t		lid;
	uint16_t		sm_lid;
	uint8_t			lmc;
	uint8_t			max_vl_num;
	uint8_t			sm_sl;
	uint8_t			subnet_timeout;
	uint8_t			init_type_reply;
	uint8_t			active_width;
	uint8_t			active_speed;
	uint8_t			phys_state;
	uint8_t			link_layer;
	uint8_t			flags;
	uint16_t		port_cap_flags2;
};

ibv_query_port: 查询RDMA端口属性
struct ibv_port_attr {
    enum ibv_port_state     state;          /* Logical port state */
    enum ibv_mtu            max_mtu;        /* Max MTU supported by port */
    enum ibv_mtu            active_mtu;     /* Actual MTU */
    int                     gid_tbl_len;    /* Length of source GID table */
    uint32_t                port_cap_flags; /* Port capabilities */
    uint32_t                max_msg_sz;     /* Maximum message size */
    uint32_t                bad_pkey_cntr;  /* Bad P_Key counter */
    uint32_t                qkey_viol_cntr; /* Q_Key violation counter */
    uint16_t                pkey_tbl_len;   /* Length of partition table */
    uint16_t                lid;            /* Base port LID */
    uint16_t                sm_lid;         /* SM LID */
    uint8_t                 lmc;            /* LMC of LID */ 
    uint8_t                 max_vl_num;     /* Maximum number of VLs */
    uint8_t                 sm_sl;          /* SM service level */
    uint8_t                 subnet_timeout; /* Subnet propagation delay */
    uint8_t                 init_type_reply;/* Type of initialization performed by SM */
    uint8_t                 active_width;   /* Currently active link width */
    uint8_t                 active_speed;   /* Currently active link speed */
    uint8_t                 phys_state;     /* Physical port state */
    uint8_t                 link_layer;     /* link layer protocol of the port */
};

struct ibv_port_attr
{
    enum ibv_port_state state;//端口状态
    enum ibv_mtu max_mtu; //端口支持的最大传输单元MTU
    enum ibv_mtu active_mtu; //当前的MTU
    int gid_tbl_len; //GID表格的长度（source global id）
    uint32_t port_cap_flags; //端口支持的容量大小
    uint32_t max_msg_sz; //最大信息长度
    uint32_t bad_pkey_cntr; //Bad P_key counter
    uint32_t qkey_viol_cntr; //Q_Key violation counter
    uint16_t pkey_tbl_len; //分区表长度
    uint16_t lid; //该端口被分配的第一个LID
    uint16_t sm_lid; //subet manager子网管理的LID
    uint8_t lmc; //LID mask control 当多个LID被分配给当前端口时使用
    uint8_t max_vl_num; //最大虚拟线路
    uint8_t sm_sl; //SM服务等级SL
    uint8_t subnet_timeout; //子网传播延时
    uint8_t init_type_reply; //SM的初始化方式
    uint8_t active_width; //当前带宽
    uint8_t active_speed; //当前速度
    uint8_t phys_state; //物理端口状态
};


网卡相关
#define UCS_NETIF_DIR                    "/sys/class/net"
#define UCS_BOND_NUM_PORTS_FILE          "bonding/ad_num_ports"
#define UCS_SOCKET_MAX_CONN_PATH         "/proc/sys/net/core/somaxconn"
/* The port space of IPv6 is shared with IPv4 */
#define UCX_PROCESS_IP_PORT_RANGE        "/proc/sys/net/ipv4/ip_local_port_range"




队列对类型: 
enum ibv_qp_type {
	IBV_QPT_RC = 2,
	IBV_QPT_UC,
	IBV_QPT_UD,
	IBV_QPT_RAW_PACKET = 8, -> 添加原始数据包QP类型，IB_QPT_RAW_PACKET允许应用程序在发送时构建完整的数据包，包括L2标头； 在接收端，硬件不会剥离任何标头。 这种QP类型是为用户空间直接访问以太网而设计的； 例如，通过自己执行 TCP/IP 的应用程序。 仅允许具有 NET_RAW 功能的进程创建原始数据包 QP（名称“原始数据包 QP”应该与 AF_PACKET / SOL_RAW 套接字进行类比）
	IBV_QPT_XRC_SEND = 9, -> 添加对 XRC QP、XRC 队列对的支持：XRC 定义了两种新类型的 QP。 发起方（或发送方）XRC QP 的行为类似于仅发送 RC QP。 XRC 发送 QP 通过现有 QP 功能进行管理。 send_wr 结构以向后兼容的方式扩展，以支持在发送 XRC QP 上发布发送，这需要指定远程 XRC SRQ。 目标或接收端 XRC QP 的行为与其他实现的 QP 不同。 可以像其他 QP 一样通过现有调用创建、修改和销毁 recv XRC QP。 qp_init_attr 结构针对 XRC QP 进行了扩展。 由于 XRC recv QP 绑定到 XRCD，而不是 PD，因此它们旨在在多个进程之间使用。 任何有权访问 XRCD 的进程都可以分配并连接 XRC recv QP。 实际的XRC recv QP 由内核分配和管理。 如果拥有进程显式销毁 XRC recv QP，则它会被销毁。 但是，如果当用户进程退出或关闭其设备时 XRC recv QP 保持打开状态，则 XRC recv QP 的生命周期与 XRCD 的生命周期相关
	IBV_QPT_XRC_RECV, -> verbs：引入驱动程序QP类型，供应商可以实现InfiniBand规范中未描述的QP类型。 动词层不知道该 QP 提供哪些服务，但它假设硬件驱动程序提供。 新的 QP 类型 IBV_QPT_DRIVER 应该用于此类 QP。 描述此 QP 的任何额外数据应存储在与此 QP 关联的硬件驱动程序的上下文中
	IBV_QPT_DRIVER = 0xff,
};



队列对属性的掩码
enum ibv_qp_attr_mask {
	IBV_QP_STATE			= 1 << 	0,
	IBV_QP_CUR_STATE		= 1 << 	1,
	IBV_QP_EN_SQD_ASYNC_NOTIFY	= 1 << 	2,
	IBV_QP_ACCESS_FLAGS		= 1 << 	3,
	IBV_QP_PKEY_INDEX		= 1 << 	4,
	IBV_QP_PORT			= 1 << 	5,
	IBV_QP_QKEY			= 1 << 	6,
	IBV_QP_AV			= 1 << 	7,
	IBV_QP_PATH_MTU			= 1 << 	8,
	IBV_QP_TIMEOUT			= 1 << 	9,
	IBV_QP_RETRY_CNT		= 1 << 10,
	IBV_QP_RNR_RETRY		= 1 << 11,
	IBV_QP_RQ_PSN			= 1 << 12,
	IBV_QP_MAX_QP_RD_ATOMIC		= 1 << 13,
	IBV_QP_ALT_PATH			= 1 << 14,
	IBV_QP_MIN_RNR_TIMER		= 1 << 15,
	IBV_QP_SQ_PSN			= 1 << 16,
	IBV_QP_MAX_DEST_RD_ATOMIC	= 1 << 17,
	IBV_QP_PATH_MIG_STATE		= 1 << 18,
	IBV_QP_CAP			= 1 << 19,
	IBV_QP_DEST_QPN			= 1 << 20,
	/* These bits were supported on older kernels, but never exposed from
	   libibverbs:
	_IBV_QP_SMAC   			= 1 << 21,
	_IBV_QP_ALT_SMAC		= 1 << 22,
	_IBV_QP_VID    			= 1 << 23,
	_IBV_QP_ALT_VID 		= 1 << 24,
	*/
	IBV_QP_RATE_LIMIT		= 1 << 25,
};



/**
 * Memory pool slow-path data. 满路径数据内存池
 */
struct ucs_mpool_data {
    size_t                 elem_size;       /* Size of element in the chunk */
    size_t                 alignment;       /* Element alignment */
    size_t                 align_offset;    /* Offset to alignment point */
    double                 grow_factor;     /* Grow factor for number of elements per chunk */
    size_t                 max_chunk_size;  /* Maximum chunk size to decide if chunk grows
                                             * only take effect on grow_factor=1 */
    unsigned               elems_per_chunk; /* Number of elements per chunk */
    unsigned               quota;           /* How many more elements can be allocated */
    int                    malloc_safe;     /* Avoid triggering malloc() during put/get */
    ucs_mpool_elem_t       *tail;           /* Free list tail */
    ucs_mpool_chunk_t      *chunks;         /* List of allocated chunks */
    const ucs_mpool_ops_t  *ops;            /* Memory pool operations */
    char                   *name;           /* Name - used for debugging */
};



UCS/UCT/TEST：重构和优化内存池基础设施。
+ 将 mpool 结构嵌入到结构中而不是指向它 - 减少对象分配/释放时的缓存未命中。
+ 添加内联分配函数。
+ 支持任意验证数据。
+ 支持对象清理功能。
+ 增强内存泄漏检查 - 打印哪些对象没有被释放



/**
 * @ingroup UCT_MD
 * @brief  Memory allocation/registration flags. 内存分配或注册的控制标记位
 */
enum uct_md_mem_flags {
    UCT_MD_MEM_FLAG_NONBLOCK    = UCS_BIT(0), /**< Hint to perform non-blocking
                                                   allocation/registration: page
                                                   mapping may be deferred until
                                                   it is accessed by the CPU or a
                                                   transport. */
    UCT_MD_MEM_FLAG_FIXED       = UCS_BIT(1), /**< Place the mapping at exactly
                                                   defined address */
    UCT_MD_MEM_FLAG_LOCK        = UCS_BIT(2), /**< Registered memory should be
                                                   locked. May incur extra cost for
                                                   registration, but memory access
                                                   is usually faster. */
    UCT_MD_MEM_FLAG_HIDE_ERRORS = UCS_BIT(3), /**< Hide errors on memory registration.
                                                   In some cases registration failure
                                                   is not an error (e. g. for merged
                                                   memory regions). */

    /* memory access flags */
    UCT_MD_MEM_ACCESS_REMOTE_PUT    = UCS_BIT(5), /**< enable remote put access */
    UCT_MD_MEM_ACCESS_REMOTE_GET    = UCS_BIT(6), /**< enable remote get access */
    UCT_MD_MEM_ACCESS_REMOTE_ATOMIC = UCS_BIT(7), /**< enable remote atomic access */
    UCT_MD_MEM_ACCESS_LOCAL_READ    = UCS_BIT(8), /**< enable local read access */
    UCT_MD_MEM_ACCESS_LOCAL_WRITE   = UCS_BIT(9), /**< enable local write access */

    /** enable local and remote access for all operations */
    UCT_MD_MEM_ACCESS_ALL =  (UCT_MD_MEM_ACCESS_REMOTE_PUT|
                              UCT_MD_MEM_ACCESS_REMOTE_GET|
                              UCT_MD_MEM_ACCESS_REMOTE_ATOMIC|
                              UCT_MD_MEM_ACCESS_LOCAL_READ|
                              UCT_MD_MEM_ACCESS_LOCAL_WRITE),

    /** enable local and remote access for put and get operations */
    UCT_MD_MEM_ACCESS_RMA = (UCT_MD_MEM_ACCESS_REMOTE_PUT|
                             UCT_MD_MEM_ACCESS_REMOTE_GET|
                             UCT_MD_MEM_ACCESS_LOCAL_READ|
                             UCT_MD_MEM_ACCESS_LOCAL_WRITE)
};


字符串操作函数: src/ucs/sys/string.c

const char *ucs_debug_get_symbol_name(void *address) -> 根据地址获取符号, 缓存地址与符号表的映射, 可用于调试调用栈
    hash_it = kh_put(ucs_debug_symbol, &ucs_debug_symbols_cache, (uintptr_t)address, &hash_extra_status);
    sym = kh_value(&ucs_debug_symbols_cache, hash_it)
    status = ucs_debug_lookup_address(address, &info)
        ret = dladdr(address, &dl_info)
        ucs_strncpy_safe(info->file.path, dl_info.dli_fname, sizeof(info->file.path))
        ucs_strncpy_safe(info->function
        ucs_strncpy_safe(info->source_file
    ucs_strncpy_safe(sym, info.function, length + 1) -> 安全拷贝字符串,最后一个字符置零('\0')
    kh_value(&ucs_debug_symbols_cache, hash_it) = sym







发送回调的调用栈:
uct_work_progress
    ucs_callbackq_dispatch
        count += cb(elem->arg) -> uct_rc_verbs_iface_progress
            uct_rc_verbs_iface_poll_tx
                uct_rc_txqp_completion_desc(&ep->super.txqp, ep->txcnt.ci + count)
                    uct_rc_txqp_completion_op(op, ucs_derived_of(op, uct_rc_iface_send_desc_t) + 1);
                        op->handler(op, resp) -> void uct_rc_ep_am_zcopy_handler
                            comp->func(comp) -> void zcopy_completion_cb(uct_completion_t *self)
                                uct_md_mem_dereg(comp->md, comp->memh)
                                desc_holder = (void *)0xDEADBEEF



常用宏:src/ucs/sys/compiler_def.h
#define UCS_F_PRINTF(fmtargN, vargN) __attribute__((format(printf, fmtargN, vargN)))

/* Unused variable */
#define UCS_V_UNUSED __attribute__((unused))

/* Aligned variable */
#define UCS_V_ALIGNED(_align) __attribute__((aligned(_align)))

/* Used for labels */
#define UCS_EMPTY_STATEMENT {}

/* Helper macro for address arithmetic in bytes */
#define UCS_PTR_BYTE_OFFSET(_ptr, _offset) \
    ((void *)((intptr_t)(_ptr) + (intptr_t)(_offset)))

/* Helper macro to calculate an address with offset equal to size of _type */
#define UCS_PTR_TYPE_OFFSET(_ptr, _type) \
    ((void *)((ucs_typeof(_type) *)(_ptr) + 1))

/* Helper macro to calculate ptr difference (_end - _start) */
#define UCS_PTR_BYTE_DIFF(_start, _end) \
    ((ptrdiff_t)((uintptr_t)(_end) - (uintptr_t)(_start)))


/**
 * Size of statically-declared array
 */
#define ucs_static_array_size(_array) \
    (sizeof(_array) / sizeof((_array)[0]))


/**
 * @return Offset of _member in _type. _type is a structure type.
 */
#define ucs_offsetof(_type, _member) \
    ((unsigned long)&( ((_type*)0)->_member ))


uct_ib_mlx5_check_completion_with_err
handle_failure
uct_dc_mlx5_iface_handle_failure
    uct_dc_mlx5_dci_keepalive_handle_failure
        ucs_queue_pull(&txqp->outstanding)



uct_rc_mlx5_iface_common_poll_rx
    uct_rc_mlx5_iface_poll_rx_cq
        uct_ib_mlx5_poll_cq uct_rc_mlx5_iface_check_rx_completion
        